{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Student Name:  Ndanu Mwatu\n",
    "* Student Pace:  Part Time\n",
    "* Date:          24th October 2023\n",
    "* Phase:         Phase 3 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image_investment-5318530_1280.jpg\" width=\"400\" height=\"50\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image by Tumisu from Pixabay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Customers Attrition Prediction\n",
    "\n",
    "**Author:** Ndanu Mwatu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline:\n",
    "1. 0 Overview\n",
    "2. 0 Business Problem\n",
    "3. 0 Data Understanding\n",
    "4. 0 Data Preparation / Preprocessing\n",
    "5. 0 Data Modelling and Evaluation\n",
    "    * 1.Logistic Regression Modelling\n",
    "    * 2.Decision Trees Modelling\n",
    "    * 3.Random Forest Modelling\n",
    "    * 4.Overall Best Model Evaluation\n",
    "6. 0 Conclusions, Recommendations and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Overview\n",
    "\n",
    "This project seeks to create a classification model to be used by the client -ABC Multinational Bank- to predict customer attrition (loss of clients) by analyzing various attributes of account holders at the Bank. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Business Problem\n",
    "\n",
    "In the recent years, ABC Multinational Bank has grown concerned over the rate of customers who exit the Bank, leading to declining profits, inability to plan for the long term, and the risk of compromised credit facilities.The Bank's management has sadly noted that about 1 in 5 customers has been leaving the Bank, but they are unable to know exactly who will leave.\n",
    "\n",
    "The Bank wants to design intervention measures to mitigate against loss of customers to their competitors, thereby ensuring maximum customer retention. Additionally, such insights would guide the Bank in mitigation against the risk of clients leaving without complete loan payments. \n",
    "\n",
    "As such, the Bank has provided data on their account holders; including past customers who have left the Bank or remained. The task is to create a classificaton model that would help the client identify customers who may leave -early enough, before they leave- that the Bank may apply appropriate mitigation measures to attract them to stay on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image_finance-586405_1280.jpg\" width=\"350\" height=\"50\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image by Gerd Altmann from Pixabay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "\n",
    "This project will utilize customer data of account holders at ABC Multinational Bank, downloaded from [Kaggle](https://www.kaggle.com/datasets/gauravtopre/bank-customer-churn-dataset) to predict customer attrition (loss of clients). The dataset contains customer attributes such as credit_score, gender, age, balance, estimated salary amongst others; as well as information on customers who have left or stayed in the Bank (Churn).\n",
    "\n",
    "In this section, we shall begin by importing necessary libraries and functions; load the data;\n",
    "and explore the dataset to gain a deeper understanding of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, log_loss\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products_number</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15634602</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15647311</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15619304</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15701354</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15737888</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>15606229</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>15569892</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>15584532</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>15682355</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>15628319</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer_id  credit_score  country  gender  age  tenure    balance  \\\n",
       "0        15634602           619   France  Female   42       2       0.00   \n",
       "1        15647311           608    Spain  Female   41       1   83807.86   \n",
       "2        15619304           502   France  Female   42       8  159660.80   \n",
       "3        15701354           699   France  Female   39       1       0.00   \n",
       "4        15737888           850    Spain  Female   43       2  125510.82   \n",
       "...           ...           ...      ...     ...  ...     ...        ...   \n",
       "9995     15606229           771   France    Male   39       5       0.00   \n",
       "9996     15569892           516   France    Male   35      10   57369.61   \n",
       "9997     15584532           709   France  Female   36       7       0.00   \n",
       "9998     15682355           772  Germany    Male   42       3   75075.31   \n",
       "9999     15628319           792   France  Female   28       4  130142.79   \n",
       "\n",
       "      products_number  credit_card  active_member  estimated_salary  churn  \n",
       "0                   1            1              1         101348.88      1  \n",
       "1                   1            0              1         112542.58      0  \n",
       "2                   3            1              0         113931.57      1  \n",
       "3                   2            0              0          93826.63      0  \n",
       "4                   1            1              1          79084.10      0  \n",
       "...               ...          ...            ...               ...    ...  \n",
       "9995                2            1              0          96270.64      0  \n",
       "9996                1            1              1         101699.77      0  \n",
       "9997                1            0              1          42085.58      1  \n",
       "9998                2            1              0          92888.52      1  \n",
       "9999                1            1              0          38190.78      0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Bank Customer Churn Prediction.csv')\n",
    "#preview the dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the dataframe, our dataset contains 10,000 rows each having 11 feature columns and 1 target column. The target column 'churn', is a 1 if the client has left the bank during some period or 0 if he/she has not.\n",
    "\n",
    "We continue the data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customer_id       10000 non-null  int64  \n",
      " 1   credit_score      10000 non-null  int64  \n",
      " 2   country           10000 non-null  object \n",
      " 3   gender            10000 non-null  object \n",
      " 4   age               10000 non-null  int64  \n",
      " 5   tenure            10000 non-null  int64  \n",
      " 6   balance           10000 non-null  float64\n",
      " 7   products_number   10000 non-null  int64  \n",
      " 8   credit_card       10000 non-null  int64  \n",
      " 9   active_member     10000 non-null  int64  \n",
      " 10  estimated_salary  10000 non-null  float64\n",
      " 11  churn             10000 non-null  int64  \n",
      "dtypes: float64(2), int64(8), object(2)\n",
      "memory usage: 937.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check dataset information \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information about the features, we note that:\n",
    "* Some features are categorical (type object) while others are numeric (type int64 and float64)\n",
    "* There are no missing values in any of the columns\n",
    "\n",
    "We then get a summary of descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products_number</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        customer_id  credit_score           age        tenure        balance  \\\n",
       "count  1.000000e+04  10000.000000  10000.000000  10000.000000   10000.000000   \n",
       "mean   1.569094e+07    650.528800     38.921800      5.012800   76485.889288   \n",
       "std    7.193619e+04     96.653299     10.487806      2.892174   62397.405202   \n",
       "min    1.556570e+07    350.000000     18.000000      0.000000       0.000000   \n",
       "25%    1.562853e+07    584.000000     32.000000      3.000000       0.000000   \n",
       "50%    1.569074e+07    652.000000     37.000000      5.000000   97198.540000   \n",
       "75%    1.575323e+07    718.000000     44.000000      7.000000  127644.240000   \n",
       "max    1.581569e+07    850.000000     92.000000     10.000000  250898.090000   \n",
       "\n",
       "       products_number  credit_card  active_member  estimated_salary  \\\n",
       "count     10000.000000  10000.00000   10000.000000      10000.000000   \n",
       "mean          1.530200      0.70550       0.515100     100090.239881   \n",
       "std           0.581654      0.45584       0.499797      57510.492818   \n",
       "min           1.000000      0.00000       0.000000         11.580000   \n",
       "25%           1.000000      0.00000       0.000000      51002.110000   \n",
       "50%           1.000000      1.00000       1.000000     100193.915000   \n",
       "75%           2.000000      1.00000       1.000000     149388.247500   \n",
       "max           4.000000      1.00000       1.000000     199992.480000   \n",
       "\n",
       "              churn  \n",
       "count  10000.000000  \n",
       "mean       0.203700  \n",
       "std        0.402769  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a summary of descriptive statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note from the descriptive statistics that;\n",
    "* The features in the numeric columns are not in the same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Counts:\n",
      "0    7963\n",
      "1    2037\n",
      "Name: churn, dtype: int64\n",
      "\n",
      "Percentages:\n",
      "0    0.7963\n",
      "1    0.2037\n",
      "Name: churn, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Exploring the distribution of the target feature (Churn)\n",
    "print(\"Raw Counts:\")\n",
    "print(df[\"churn\"].value_counts())\n",
    "print()\n",
    "print(\"Percentages:\")\n",
    "print(df[\"churn\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that:\n",
    "\n",
    "* This is an imbalanced dataset, since customers who have left the bank are relatively fewer than those who stay. \n",
    "\n",
    "* About 20% of customers have left the bank at some point, while 79.6% have not left. \n",
    "\n",
    "* Therefore, if we had a 'dummy' model, that always predicted that no customer would leave the bank(class 0), it would be 79.6% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Data Preparation / Preprocessing\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "To prepare the data for analysis, the following steps are carried out;\n",
    "* Define X (predictors) and y (target)\n",
    "* Split the data into training and test sets \n",
    "* Preprocessing/cleaning:\n",
    "    * check for missing values\n",
    "    * deal with categorical data using one hot encoding \n",
    "    * Normalize/standardize numeric features\n",
    "\n",
    "Preprocessing is carried out after splitting the data i.e. separately for the train and test sets; to prevent data leakage into the test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1 Define X and y**\n",
    "\n",
    "* We set y as the as the target variable 'churn'\n",
    "* We set X as the predictors. We exclude the target variable. We also exclude customer_id column as it's not a true feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['churn']\n",
    "X = df.drop(columns=['churn', 'customer_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2 Split the data into training and test sets**\n",
    "\n",
    "We use a random_state of 42 for reproducibility; and the default 75% train/25% test proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3 Preprocessing**\n",
    "\n",
    "Preprocessing is done for the separate train and test sets to avoid data leakage thus allow proper generalizing\n",
    "\n",
    "**i. Check for missing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "credit_score        0\n",
       "country             0\n",
       "gender              0\n",
       "age                 0\n",
       "tenure              0\n",
       "balance             0\n",
       "products_number     0\n",
       "credit_card         0\n",
       "active_member       0\n",
       "estimated_salary    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the EDA stage, we saw there was no missing data and this is confirmed;\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii. Deal with categorical data - using one hot encoding**\n",
    "\n",
    "As seen during EDA, some features have categorical data (object data type) and need to be converted to numeric data types for modelling purposes, using dummy one hot encoded variables. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7500 entries, 4901 to 7270\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   credit_score      7500 non-null   int64  \n",
      " 1   country           7500 non-null   object \n",
      " 2   gender            7500 non-null   object \n",
      " 3   age               7500 non-null   int64  \n",
      " 4   tenure            7500 non-null   int64  \n",
      " 5   balance           7500 non-null   float64\n",
      " 6   products_number   7500 non-null   int64  \n",
      " 7   credit_card       7500 non-null   int64  \n",
      " 8   active_member     7500 non-null   int64  \n",
      " 9   estimated_salary  7500 non-null   float64\n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 644.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#check categorical and numeric columns\n",
    "X_train.info() #preprocessing to be done separately for train and test data to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6698</th>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9805</th>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      country  gender\n",
       "4901   France    Male\n",
       "4375  Germany    Male\n",
       "6698   France  Female\n",
       "9805   France    Male\n",
       "1101    Spain    Male\n",
       "...       ...     ...\n",
       "5734   France    Male\n",
       "5191   France  Female\n",
       "5390   France  Female\n",
       "860    France    Male\n",
       "7270  Germany    Male\n",
       "\n",
       "[7500 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the categorical data columns\n",
    "X_train_categorical = X_train.select_dtypes(exclude=[\"int64\", \"float64\"]).copy()\n",
    "X_train_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products_number</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>673</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>178058.06</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21063.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>850</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>60880.68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31825.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6698</th>\n",
       "      <td>725</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61326.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9805</th>\n",
       "      <td>644</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>174571.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43943.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>703</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50679.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>768</td>\n",
       "      <td>54</td>\n",
       "      <td>8</td>\n",
       "      <td>69712.74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69381.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>682</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>706.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>735</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92220.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>667</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>190227.46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97508.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>697</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>147910.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53581.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_score  age  tenure    balance  products_number  credit_card  \\\n",
       "4901           673   59       0  178058.06                2            0   \n",
       "4375           850   41       8   60880.68                1            1   \n",
       "6698           725   31       6       0.00                1            0   \n",
       "9805           644   33       7  174571.36                1            0   \n",
       "1101           703   29       9       0.00                2            1   \n",
       "...            ...  ...     ...        ...              ...          ...   \n",
       "5734           768   54       8   69712.74                1            1   \n",
       "5191           682   58       1       0.00                1            1   \n",
       "5390           735   38       1       0.00                3            0   \n",
       "860            667   43       8  190227.46                1            1   \n",
       "7270           697   51       1  147910.30                1            1   \n",
       "\n",
       "      active_member  estimated_salary  \n",
       "4901              1          21063.71  \n",
       "4375              0          31825.84  \n",
       "6698              0          61326.43  \n",
       "9805              1          43943.09  \n",
       "1101              0          50679.48  \n",
       "...             ...               ...  \n",
       "5734              1          69381.05  \n",
       "5191              1            706.50  \n",
       "5390              0          92220.12  \n",
       "860               0          97508.04  \n",
       "7270              1          53581.14  \n",
       "\n",
       "[7500 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the numeric data columns\n",
    "X_train_numeric = X_train.select_dtypes(include='number').copy()\n",
    "X_train_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6698</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9805</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      France  Germany  Spain  Female  Male\n",
       "4901     1.0      0.0    0.0     0.0   1.0\n",
       "4375     0.0      1.0    0.0     0.0   1.0\n",
       "6698     1.0      0.0    0.0     1.0   0.0\n",
       "9805     1.0      0.0    0.0     0.0   1.0\n",
       "1101     0.0      0.0    1.0     0.0   1.0\n",
       "...      ...      ...    ...     ...   ...\n",
       "5734     1.0      0.0    0.0     0.0   1.0\n",
       "5191     1.0      0.0    0.0     1.0   0.0\n",
       "5390     1.0      0.0    0.0     1.0   0.0\n",
       "860      1.0      0.0    0.0     0.0   1.0\n",
       "7270     0.0      1.0    0.0     0.0   1.0\n",
       "\n",
       "[7500 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert categorical variables into dummy one-hot encoded variables\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "ohe.fit(X_train_categorical)\n",
    "X_train_ohe = pd.DataFrame(\n",
    "    ohe.transform(X_train_categorical),\n",
    "    index=X_train_categorical.index,\n",
    "    columns=np.hstack(ohe.categories_)\n",
    ")\n",
    "X_train_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products_number</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>673</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>178058.06</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21063.71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>850</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>60880.68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31825.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6698</th>\n",
       "      <td>725</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61326.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9805</th>\n",
       "      <td>644</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>174571.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43943.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>703</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50679.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>768</td>\n",
       "      <td>54</td>\n",
       "      <td>8</td>\n",
       "      <td>69712.74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69381.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>682</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>706.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>735</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92220.12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>667</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>190227.46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97508.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>697</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>147910.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53581.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_score  age  tenure    balance  products_number  credit_card  \\\n",
       "4901           673   59       0  178058.06                2            0   \n",
       "4375           850   41       8   60880.68                1            1   \n",
       "6698           725   31       6       0.00                1            0   \n",
       "9805           644   33       7  174571.36                1            0   \n",
       "1101           703   29       9       0.00                2            1   \n",
       "...            ...  ...     ...        ...              ...          ...   \n",
       "5734           768   54       8   69712.74                1            1   \n",
       "5191           682   58       1       0.00                1            1   \n",
       "5390           735   38       1       0.00                3            0   \n",
       "860            667   43       8  190227.46                1            1   \n",
       "7270           697   51       1  147910.30                1            1   \n",
       "\n",
       "      active_member  estimated_salary  France  Germany  Spain  Female  Male  \n",
       "4901              1          21063.71     1.0      0.0    0.0     0.0   1.0  \n",
       "4375              0          31825.84     0.0      1.0    0.0     0.0   1.0  \n",
       "6698              0          61326.43     1.0      0.0    0.0     1.0   0.0  \n",
       "9805              1          43943.09     1.0      0.0    0.0     0.0   1.0  \n",
       "1101              0          50679.48     0.0      0.0    1.0     0.0   1.0  \n",
       "...             ...               ...     ...      ...    ...     ...   ...  \n",
       "5734              1          69381.05     1.0      0.0    0.0     0.0   1.0  \n",
       "5191              1            706.50     1.0      0.0    0.0     1.0   0.0  \n",
       "5390              0          92220.12     1.0      0.0    0.0     1.0   0.0  \n",
       "860               0          97508.04     1.0      0.0    0.0     0.0   1.0  \n",
       "7270              1          53581.14     0.0      1.0    0.0     0.0   1.0  \n",
       "\n",
       "[7500 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At this stage, we concatenate the onehot encoded data and the numeric data  \n",
    "X_train_full = pd.concat([X_train_numeric, X_train_ohe], axis=1)\n",
    "X_train_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii. Normalizing/standardizing numeric features**\n",
    "\n",
    "Since the features are on different scales,as seen during EDA, some features may impact the model more heavily than others. We thus normalize all features to a consistent scale using a StandardScaler. This scaled data will be used for model types that require scaling i.e. Logistic regression. The unscaled data will be used in model types that don't require scaling i.e Decision trees and Random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products_number</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>0.218351</td>\n",
       "      <td>1.916619</td>\n",
       "      <td>-1.731689</td>\n",
       "      <td>1.629928</td>\n",
       "      <td>0.813111</td>\n",
       "      <td>-1.539736</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>-1.382844</td>\n",
       "      <td>1.000533</td>\n",
       "      <td>-0.577761</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.911867</td>\n",
       "      <td>0.911867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>2.057280</td>\n",
       "      <td>0.202109</td>\n",
       "      <td>1.041750</td>\n",
       "      <td>-0.246244</td>\n",
       "      <td>-0.911043</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>-1.031152</td>\n",
       "      <td>-1.195890</td>\n",
       "      <td>-0.999467</td>\n",
       "      <td>1.730820</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.911867</td>\n",
       "      <td>0.911867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6698</th>\n",
       "      <td>0.758602</td>\n",
       "      <td>-0.750397</td>\n",
       "      <td>0.348390</td>\n",
       "      <td>-1.221027</td>\n",
       "      <td>-0.911043</td>\n",
       "      <td>-1.539736</td>\n",
       "      <td>-1.031152</td>\n",
       "      <td>-0.683422</td>\n",
       "      <td>1.000533</td>\n",
       "      <td>-0.577761</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>1.096651</td>\n",
       "      <td>-1.096651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9805</th>\n",
       "      <td>-0.082942</td>\n",
       "      <td>-0.559895</td>\n",
       "      <td>0.695070</td>\n",
       "      <td>1.574101</td>\n",
       "      <td>-0.911043</td>\n",
       "      <td>-1.539736</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>-0.985396</td>\n",
       "      <td>1.000533</td>\n",
       "      <td>-0.577761</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.911867</td>\n",
       "      <td>0.911867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>0.530034</td>\n",
       "      <td>-0.940898</td>\n",
       "      <td>1.388429</td>\n",
       "      <td>-1.221027</td>\n",
       "      <td>0.813111</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>-1.031152</td>\n",
       "      <td>-0.868375</td>\n",
       "      <td>-0.999467</td>\n",
       "      <td>-0.577761</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>-0.911867</td>\n",
       "      <td>0.911867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>1.205347</td>\n",
       "      <td>1.440366</td>\n",
       "      <td>1.041750</td>\n",
       "      <td>-0.104830</td>\n",
       "      <td>-0.911043</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>-0.543502</td>\n",
       "      <td>1.000533</td>\n",
       "      <td>-0.577761</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.911867</td>\n",
       "      <td>0.911867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>0.311856</td>\n",
       "      <td>1.821368</td>\n",
       "      <td>-1.385009</td>\n",
       "      <td>-1.221027</td>\n",
       "      <td>-0.911043</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>-1.736478</td>\n",
       "      <td>1.000533</td>\n",
       "      <td>-0.577761</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>1.096651</td>\n",
       "      <td>-1.096651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.862496</td>\n",
       "      <td>-0.083643</td>\n",
       "      <td>-1.385009</td>\n",
       "      <td>-1.221027</td>\n",
       "      <td>2.537266</td>\n",
       "      <td>-1.539736</td>\n",
       "      <td>-1.031152</td>\n",
       "      <td>-0.146754</td>\n",
       "      <td>1.000533</td>\n",
       "      <td>-0.577761</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>1.096651</td>\n",
       "      <td>-1.096651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.156015</td>\n",
       "      <td>0.392610</td>\n",
       "      <td>1.041750</td>\n",
       "      <td>1.824777</td>\n",
       "      <td>-0.911043</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>-1.031152</td>\n",
       "      <td>-0.054895</td>\n",
       "      <td>1.000533</td>\n",
       "      <td>-0.577761</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.911867</td>\n",
       "      <td>0.911867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>0.467698</td>\n",
       "      <td>1.154615</td>\n",
       "      <td>-1.385009</td>\n",
       "      <td>1.147221</td>\n",
       "      <td>-0.911043</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>-0.817969</td>\n",
       "      <td>-0.999467</td>\n",
       "      <td>1.730820</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.911867</td>\n",
       "      <td>0.911867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_score       age    tenure   balance  products_number  \\\n",
       "4901      0.218351  1.916619 -1.731689  1.629928         0.813111   \n",
       "4375      2.057280  0.202109  1.041750 -0.246244        -0.911043   \n",
       "6698      0.758602 -0.750397  0.348390 -1.221027        -0.911043   \n",
       "9805     -0.082942 -0.559895  0.695070  1.574101        -0.911043   \n",
       "1101      0.530034 -0.940898  1.388429 -1.221027         0.813111   \n",
       "...            ...       ...       ...       ...              ...   \n",
       "5734      1.205347  1.440366  1.041750 -0.104830        -0.911043   \n",
       "5191      0.311856  1.821368 -1.385009 -1.221027        -0.911043   \n",
       "5390      0.862496 -0.083643 -1.385009 -1.221027         2.537266   \n",
       "860       0.156015  0.392610  1.041750  1.824777        -0.911043   \n",
       "7270      0.467698  1.154615 -1.385009  1.147221        -0.911043   \n",
       "\n",
       "      credit_card  active_member  estimated_salary    France   Germany  \\\n",
       "4901    -1.539736       0.969789         -1.382844  1.000533 -0.577761   \n",
       "4375     0.649462      -1.031152         -1.195890 -0.999467  1.730820   \n",
       "6698    -1.539736      -1.031152         -0.683422  1.000533 -0.577761   \n",
       "9805    -1.539736       0.969789         -0.985396  1.000533 -0.577761   \n",
       "1101     0.649462      -1.031152         -0.868375 -0.999467 -0.577761   \n",
       "...           ...            ...               ...       ...       ...   \n",
       "5734     0.649462       0.969789         -0.543502  1.000533 -0.577761   \n",
       "5191     0.649462       0.969789         -1.736478  1.000533 -0.577761   \n",
       "5390    -1.539736      -1.031152         -0.146754  1.000533 -0.577761   \n",
       "860      0.649462      -1.031152         -0.054895  1.000533 -0.577761   \n",
       "7270     0.649462       0.969789         -0.817969 -0.999467  1.730820   \n",
       "\n",
       "         Spain    Female      Male  \n",
       "4901 -0.577350 -0.911867  0.911867  \n",
       "4375 -0.577350 -0.911867  0.911867  \n",
       "6698 -0.577350  1.096651 -1.096651  \n",
       "9805 -0.577350 -0.911867  0.911867  \n",
       "1101  1.732051 -0.911867  0.911867  \n",
       "...        ...       ...       ...  \n",
       "5734 -0.577350 -0.911867  0.911867  \n",
       "5191 -0.577350  1.096651 -1.096651  \n",
       "5390 -0.577350  1.096651 -1.096651  \n",
       "860  -0.577350 -0.911867  0.911867  \n",
       "7270 -0.577350 -0.911867  0.911867  \n",
       "\n",
       "[7500 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit to the training data numeric features\n",
    "scaler.fit(X_train_full)\n",
    "# Transform the training data\n",
    "X_train_full_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_train_full),\n",
    "    index=X_train_full.index,\n",
    "    columns=X_train_full.columns\n",
    ")\n",
    "X_train_full_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iv. Preprocess the test data separately**\n",
    "\n",
    "* The test data is preprocessed separately to avoid data leakage. The same preprocessing steps carried out for training data apply, paying attention not to fit transformers on test data.\n",
    "* Test data will be used to evaluate the model's performance on unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products_number</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>-0.581635</td>\n",
       "      <td>-0.655146</td>\n",
       "      <td>-0.691649</td>\n",
       "      <td>0.327418</td>\n",
       "      <td>0.813111</td>\n",
       "      <td>-1.539736</td>\n",
       "      <td>-1.031152</td>\n",
       "      <td>-1.022827</td>\n",
       "      <td>-0.999467</td>\n",
       "      <td>1.730820</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.911867</td>\n",
       "      <td>0.911867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>-0.301120</td>\n",
       "      <td>0.392610</td>\n",
       "      <td>-1.385009</td>\n",
       "      <td>-1.221027</td>\n",
       "      <td>0.813111</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>0.794069</td>\n",
       "      <td>1.000533</td>\n",
       "      <td>-0.577761</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.911867</td>\n",
       "      <td>0.911867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>-0.529688</td>\n",
       "      <td>0.487861</td>\n",
       "      <td>-0.344970</td>\n",
       "      <td>-1.221027</td>\n",
       "      <td>0.813111</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>-1.031152</td>\n",
       "      <td>-0.731457</td>\n",
       "      <td>-0.999467</td>\n",
       "      <td>-0.577761</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>1.096651</td>\n",
       "      <td>-1.096651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>-1.516684</td>\n",
       "      <td>1.916619</td>\n",
       "      <td>1.041750</td>\n",
       "      <td>0.686762</td>\n",
       "      <td>0.813111</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>1.216203</td>\n",
       "      <td>-0.999467</td>\n",
       "      <td>1.730820</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.911867</td>\n",
       "      <td>0.911867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>-0.955654</td>\n",
       "      <td>-1.131399</td>\n",
       "      <td>0.695070</td>\n",
       "      <td>0.780331</td>\n",
       "      <td>-0.911043</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>0.243229</td>\n",
       "      <td>-0.999467</td>\n",
       "      <td>-0.577761</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>1.096651</td>\n",
       "      <td>-1.096651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4862</th>\n",
       "      <td>-0.072553</td>\n",
       "      <td>1.535617</td>\n",
       "      <td>-1.385009</td>\n",
       "      <td>0.919320</td>\n",
       "      <td>-0.911043</td>\n",
       "      <td>-1.539736</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>-1.451778</td>\n",
       "      <td>-0.999467</td>\n",
       "      <td>-0.577761</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>1.096651</td>\n",
       "      <td>-1.096651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7025</th>\n",
       "      <td>-0.862150</td>\n",
       "      <td>1.154615</td>\n",
       "      <td>-0.691649</td>\n",
       "      <td>-1.221027</td>\n",
       "      <td>2.537266</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>-1.031152</td>\n",
       "      <td>-0.444417</td>\n",
       "      <td>-0.999467</td>\n",
       "      <td>-0.577761</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>1.096651</td>\n",
       "      <td>-1.096651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7647</th>\n",
       "      <td>1.205347</td>\n",
       "      <td>-1.321900</td>\n",
       "      <td>-1.731689</td>\n",
       "      <td>0.034202</td>\n",
       "      <td>-0.911043</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>-1.604287</td>\n",
       "      <td>1.000533</td>\n",
       "      <td>-0.577761</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.911867</td>\n",
       "      <td>0.911867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>0.394972</td>\n",
       "      <td>-0.274144</td>\n",
       "      <td>0.348390</td>\n",
       "      <td>0.547918</td>\n",
       "      <td>-0.911043</td>\n",
       "      <td>-1.539736</td>\n",
       "      <td>-1.031152</td>\n",
       "      <td>-0.336586</td>\n",
       "      <td>1.000533</td>\n",
       "      <td>-0.577761</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>1.096651</td>\n",
       "      <td>-1.096651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-0.498519</td>\n",
       "      <td>-1.321900</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>1.305262</td>\n",
       "      <td>0.813111</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>-0.733793</td>\n",
       "      <td>-0.999467</td>\n",
       "      <td>1.730820</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>1.096651</td>\n",
       "      <td>-1.096651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_score       age    tenure   balance  products_number  \\\n",
       "6252     -0.581635 -0.655146 -0.691649  0.327418         0.813111   \n",
       "4684     -0.301120  0.392610 -1.385009 -1.221027         0.813111   \n",
       "1731     -0.529688  0.487861 -0.344970 -1.221027         0.813111   \n",
       "4742     -1.516684  1.916619  1.041750  0.686762         0.813111   \n",
       "4521     -0.955654 -1.131399  0.695070  0.780331        -0.911043   \n",
       "...            ...       ...       ...       ...              ...   \n",
       "4862     -0.072553  1.535617 -1.385009  0.919320        -0.911043   \n",
       "7025     -0.862150  1.154615 -0.691649 -1.221027         2.537266   \n",
       "7647      1.205347 -1.321900 -1.731689  0.034202        -0.911043   \n",
       "7161      0.394972 -0.274144  0.348390  0.547918        -0.911043   \n",
       "73       -0.498519 -1.321900  0.001710  1.305262         0.813111   \n",
       "\n",
       "      credit_card  active_member  estimated_salary    France   Germany  \\\n",
       "6252    -1.539736      -1.031152         -1.022827 -0.999467  1.730820   \n",
       "4684     0.649462       0.969789          0.794069  1.000533 -0.577761   \n",
       "1731     0.649462      -1.031152         -0.731457 -0.999467 -0.577761   \n",
       "4742     0.649462       0.969789          1.216203 -0.999467  1.730820   \n",
       "4521     0.649462       0.969789          0.243229 -0.999467 -0.577761   \n",
       "...           ...            ...               ...       ...       ...   \n",
       "4862    -1.539736       0.969789         -1.451778 -0.999467 -0.577761   \n",
       "7025     0.649462      -1.031152         -0.444417 -0.999467 -0.577761   \n",
       "7647     0.649462       0.969789         -1.604287  1.000533 -0.577761   \n",
       "7161    -1.539736      -1.031152         -0.336586  1.000533 -0.577761   \n",
       "73       0.649462       0.969789         -0.733793 -0.999467  1.730820   \n",
       "\n",
       "         Spain    Female      Male  \n",
       "6252 -0.577350 -0.911867  0.911867  \n",
       "4684 -0.577350 -0.911867  0.911867  \n",
       "1731  1.732051  1.096651 -1.096651  \n",
       "4742 -0.577350 -0.911867  0.911867  \n",
       "4521  1.732051  1.096651 -1.096651  \n",
       "...        ...       ...       ...  \n",
       "4862  1.732051  1.096651 -1.096651  \n",
       "7025  1.732051  1.096651 -1.096651  \n",
       "7647 -0.577350 -0.911867  0.911867  \n",
       "7161 -0.577350  1.096651 -1.096651  \n",
       "73   -0.577350  1.096651 -1.096651  \n",
       "\n",
       "[2500 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess test data separately \n",
    "\n",
    "# i. Deal with categorical data for test data - using one hot encoding\n",
    "\n",
    "# Separate the categorical test data\n",
    "X_test_categorical = X_test.select_dtypes(exclude=[\"int64\", \"float64\"]).copy()\n",
    "\n",
    "# Separate the numeric test data\n",
    "X_test_numeric = X_test.select_dtypes(include='number').copy()\n",
    "\n",
    "# convert categorical test variables into dummy one-hot encoded variables\n",
    "X_test_ohe = pd.DataFrame(\n",
    "    ohe.transform(X_test_categorical),\n",
    "    index=X_test_categorical.index,\n",
    "    columns=np.hstack(ohe.categories_)\n",
    ")\n",
    "\n",
    "# at this stage we concatenate the one hot encoded data and the numeric data\n",
    "X_test_full = pd.concat([X_test_numeric, X_test_ohe], axis=1)\n",
    "\n",
    "# we normalize/standardize the test data\n",
    "X_test_full_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test_full),\n",
    "    index=X_test_full.index,\n",
    "    columns=X_test_full.columns\n",
    ")\n",
    "\n",
    "X_test_full_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Data Modeling and Evaluation \n",
    "**Introduction**\n",
    "\n",
    "In order to bring clarity to the Client (ABC Bank), on the question of *'Which customers are likely to leave ABC Bank?'* we shall build and analyse several models; then propose for use to the client, the best performing one.  \n",
    "\n",
    "3 types of models shall be built as listed below;\n",
    "1. Logistic regression models\n",
    "2. Decision Trees models\n",
    "3. Random Forest models\n",
    "\n",
    "**Iterative Approach**\n",
    "\n",
    "An iterative approach will be adopted for data modelling, whereby, for each model type a baseline model will be prepared, followed by tuning of hyperparameters in creating iterative models and selecting the best estimator for that model type. This selection of the best performing classifier will be based on the performance as gauged by the evaluation metrics. Finally, we shall identify the overall best performing classifier and evaluate it's performance on test data. \n",
    "\n",
    "The modelling will follow this outlined fashion;\n",
    "\n",
    "    i. Logistic Regression Modelling\n",
    "        -Establish Baseline Logistic Regression model\n",
    "        -Create Iterative Logistic Regression models - and determine the best one \n",
    "    ii. Decision Trees Modelling\n",
    "        -Establish Baseline Decision Tree model\n",
    "        -Create Iterative Decision Tree models - and determine the best one \n",
    "    iii. Random Forest Modelling\n",
    "        -Establish Baseline Random Forest model\n",
    "        -Create Optimal Random Forest Iterative Model - using GridSearchCV\n",
    "        -Investigate Feature Importances of the Random Forest Models\n",
    "    iv. Evaluate the Overall Best Model    \n",
    "\n",
    "**Evaluation Metrics of models performance**\n",
    "\n",
    "For this project we shall use log loss and cross_val_score on the training data; to evaluate and compare the various models performance during iterative processes; as well as for comparing the different model types performance. A lower log loss would indicate a better performing model. Therefore, as we tune the hyperparameters of the various models, we will be hoping to minimize log loss.\n",
    "\n",
    "We shall make use of ROC curve and AUC, when investigating the best hyperparameters for some models.\n",
    "\n",
    "At the final stage, the overall best model shall be assessed using other evaluation metrics i.e.  Precision, Recall, Accuracy and f1 Score. A confusion matrix shall also be displayed for the overall best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image_success-2081168_1280.jpg\" width=\"400\" height=\"50\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image by ar130405 from Pixabay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Logistic Regression Modelling\n",
    "\n",
    "The first type of classification model we shall build is Logistic Regression Models. We will commence with a baseline model, followed by several iterations to tune the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1.1 Build a Baseline Logistic Regression Model**\n",
    "\n",
    "We start by establishing a baseline logistic regression model that makes use of the preprocessed data before scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48077734628995605"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a LogisticRegression with random_state=42 for reproducibility\n",
    "logreg_baseline_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Use cross_val_score with scoring=\"neg_log_loss\" to evaluate the model on unscaled training data\n",
    "logreg_baseline_neg_log_loss_cv = cross_val_score(\n",
    "    logreg_baseline_model,\n",
    "    X_train_full,\n",
    "    y_train,\n",
    "    scoring=\"neg_log_loss\"\n",
    ")\n",
    "logreg_baseline_log_loss = -(logreg_baseline_neg_log_loss_cv.mean())\n",
    "logreg_baseline_log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.400963495898722"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log_loss of a 'dummy' model that would always predict the majority class (class 0)\n",
    "log_loss(y_train, np.zeros(len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of performance of logistic regression baseline model**\n",
    "\n",
    "The logistic regression baseline model has a log loss of 0.48. \n",
    "For a 'dummy' model that would predict the majority class all the time (class 0), the log loss would be 7.4 (as illustrated above), so the baseline model is better than such a 'dummy' model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1.2 Build iterative Logistic Regression Models**\n",
    "\n",
    "We then build iterative logistic regression models, with an aim to improve performance i.e. we desire to reduce the log loss by tuning the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1.2.1 1st iterative logistic regression model - uses scaled data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4331177672066976"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a LogisticRegression with random_state=42 for reproducibility\n",
    "logreg_model_1st_iteration = LogisticRegression(random_state=42)\n",
    "\n",
    "# Use cross_val_score with scoring=\"neg_log_loss\" to evaluate the model on the scaled training data\n",
    "logreg_1st_iter_neg_log_loss_cv = cross_val_score(\n",
    "    logreg_model_1st_iteration,\n",
    "    X_train_full_scaled,\n",
    "    y_train,\n",
    "    scoring=\"neg_log_loss\"\n",
    ")\n",
    "logreg_1st_iter_log_loss = -(logreg_1st_iter_neg_log_loss_cv.mean())\n",
    "logreg_1st_iter_log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of performance of 1st iteration of logistic regression model - addressing data scaling**\n",
    "\n",
    "This first iterative model that uses scaled data fares better with a log loss of 0.43 as compared to the baseline model that doesn't make use of scaled data and results in a log loss of 0.48. There is an improvement in performance as log loss reduces by 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1.2.2  2nd iterative logistic regression model - uses SMOTE to address class imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "0    5960\n",
      "1    1540\n",
      "Name: churn, dtype: int64\n",
      "Synthetic sample class distribution: \n",
      "\n",
      "1    5960\n",
      "0    5960\n",
      "Name: churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Utilize SMOTE on the scaled data to address class imbalance \n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_full_scaled, y_train)\n",
    "\n",
    "# Preview original class distribution\n",
    "print('Original class distribution:')\n",
    "print(y_train.value_counts()) \n",
    "\n",
    "# Preview synthetic sample class distribution\n",
    "print('Synthetic sample class distribution: \\n')\n",
    "print(pd.Series(y_train_resampled).value_counts()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5751939414785899"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a LogisticRegression with random_state=42 for reproducibility\n",
    "logreg_model_2nd_iteration = LogisticRegression(random_state=42)\n",
    "\n",
    "# Use cross_val_score with scoring=\"neg_log_loss\" to evaluate the model on preprocessed training data\n",
    "logreg_2nd_iter_neg_log_loss_cv = cross_val_score(\n",
    "    logreg_model_2nd_iteration,\n",
    "    X_train_resampled,\n",
    "    y_train_resampled,\n",
    "    scoring=\"neg_log_loss\"\n",
    ")\n",
    "\n",
    "logreg_2nd_iter_log_loss = -(logreg_2nd_iter_neg_log_loss_cv.mean())\n",
    "logreg_2nd_iter_log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of performance of 2nd iteration of logistic regression model - addressing class imbalance**\n",
    "\n",
    "The second iterative model that uses SMOTE to address class imbalance, fails to make an improvement. It has a log loss of approximately 0.57 therefore performs poorly compared to both the 1st iterative model that uses scaled data (log loss of 0.43) and the baseline logistic model (log loss of 0.48)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1.2.3  3rd iterative logistic regression model - SMOTE with different sampling strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "0    5960\n",
      "1    1540\n",
      "Name: churn, dtype: int64\n",
      "Synthetic sample class distribution: \n",
      "\n",
      "0    5960\n",
      "1    1788\n",
      "Name: churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# This model iteration utilizes SMOTE with a different sampling ratio (0.3) i.e. ratio of \n",
    "# the number of samples in the minority class over the number of samples in the majority class\n",
    "# after resampling\n",
    "smote2 = SMOTE(random_state=42, sampling_strategy=0.3)\n",
    "X_train_resampled2, y_train_resampled2 = smote2.fit_resample(X_train_full_scaled, y_train)\n",
    "\n",
    "# Preview original class distribution\n",
    "print('Original class distribution:')\n",
    "print(y_train.value_counts()) \n",
    "\n",
    "# Preview synthetic sample class distribution\n",
    "print('Synthetic sample class distribution: \\n')\n",
    "print(pd.Series(y_train_resampled2).value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45945921657886996"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a LogisticRegression with random_state=42 for reproducibility\n",
    "logreg_model_3rd_iteration = LogisticRegression(random_state=42)\n",
    "\n",
    "# Use cross_val_score with scoring=\"neg_log_loss\" to evaluate the model on preprocessed training data\n",
    "logreg_3rd_iter_neg_log_loss_cv = cross_val_score(\n",
    "    logreg_model_3rd_iteration,\n",
    "    X_train_resampled2,\n",
    "    y_train_resampled2,\n",
    "    scoring=\"neg_log_loss\"\n",
    ")\n",
    "\n",
    "logreg_3rd_iter_log_loss = -(logreg_3rd_iter_neg_log_loss_cv.mean())\n",
    "logreg_3rd_iter_log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of performance of 3rd iteration of logistic regression model - SMOTE with different sampling strategy**\n",
    "\n",
    "The third iterative model that uses a different sampling strategy of 0.3 on SMOTE i.e.the number of samples in the minority class over the number of samples in the majority class after resampling, offers a slight improvement(log loss of approx 0.46) from the previous SMOTE model (log loss of 0.57). Nonetheless, the 1st iterative model that uses scaled data (log loss of 0.43) fares better compared to this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1.2.4  4th iterative logistic regression model - reduce regularization by increasing C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4331223599333119"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a LogisticRegression with random_state=42 for reproducibility\n",
    "logreg_model_4th_iteration = LogisticRegression(random_state=42, C=1e5)\n",
    "\n",
    "# Use cross_val_score with scoring=\"neg_log_loss\" to evaluate the model on preprocessed training data\n",
    "logreg_4th_iter_neg_log_loss_cv = cross_val_score(\n",
    "    logreg_model_4th_iteration,\n",
    "    X_train_full_scaled,\n",
    "    y_train,\n",
    "    scoring=\"neg_log_loss\"\n",
    ")\n",
    "logreg_4th_iter_log_loss = -(logreg_4th_iter_neg_log_loss_cv.mean())\n",
    "logreg_4th_iter_log_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of performance of 4th iteration of logistic regression model - reduce regularization by increasing C**\n",
    "\n",
    "The fourth iterative model aims to address underfitting if at all present in the model, by reducing regularization (via increasing of the C parameter).  With a log loss of 0.433122 it is almost in the range of our best performing model though offering just a slightly worse performance than this best model so far (the 1st iterative model that uses scaled data with a log loss of 0.433117)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1.2.5  5th iterative logistic regression model - increase regularization by decreasing C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4330883400318517"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a LogisticRegression with random_state=42 for reproducibility\n",
    "logreg_model_5th_iteration = LogisticRegression(random_state=42, C=0.1)\n",
    "\n",
    "# Use cross_val_score with scoring=\"neg_log_loss\" to evaluate the model on preprocessed training data\n",
    "logreg_5th_iter_neg_log_loss_cv = cross_val_score(\n",
    "    logreg_model_5th_iteration,\n",
    "    X_train_full_scaled,\n",
    "    y_train,\n",
    "    scoring=\"neg_log_loss\"\n",
    ")\n",
    "logreg_5th_iter_log_loss = -(logreg_5th_iter_neg_log_loss_cv.mean())\n",
    "logreg_5th_iter_log_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of performance of 5th iteration of logistic regression model - increase regularization by decreasing C**\n",
    "\n",
    "The default C is 1.0, we reduce it slightly to 0.1 with an aim to increase regularization, therefore address any overfitting if present in this 5th iterative model. This model with a log loss of 0.433088 performs slightly better than the previously best model(the 1st iterative model that uses scaled data with a log loss of 0.433117) though it is only a very slight improvement in the magnitude of 0.00003.\n",
    "Henceforth, we use this parameter in the upcoming model iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1.2.6  6th iterative logistic regression model - use a different solver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43305474304803065"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a LogisticRegression with random_state=42 for reproducibility\n",
    "logreg_model_6th_iteration = LogisticRegression(\n",
    "    random_state=42,\n",
    "    C=0.1,\n",
    "    solver=\"saga\",\n",
    "    penalty=\"elasticnet\",\n",
    "    l1_ratio=0.5\n",
    ")\n",
    "\n",
    "# Use cross_val_score with scoring=\"neg_log_loss\" to evaluate the model on preprocessed training data\n",
    "logreg_6th_iter_neg_log_loss_cv = cross_val_score(\n",
    "    logreg_model_6th_iteration,\n",
    "    X_train_full_scaled,\n",
    "    y_train,\n",
    "    scoring=\"neg_log_loss\"\n",
    ")\n",
    "logreg_6th_iter_log_loss = -(logreg_6th_iter_neg_log_loss_cv.mean())\n",
    "logreg_6th_iter_log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of performance of 6th iteration of logistic regression model - use a different solver**\n",
    "\n",
    "The default solver for ligistic regression models that we have been using is 'lbfgs'. We try a different solver i.e. 'saga', with a penalty='elasticnet' and l1_ratio=0.5.This model with a log loss of 0.433054 performs slightly better than the previously best model(the 5th iterative model that increases regularization with a log loss of 0.433088) though it is only a very slight improvement in the magnitude of 0.000034. This is the best of the logistic regression models so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1.3 Summary on Logistic Regression Modelling**\n",
    "\n",
    "We built a baseline model with unscaled data (log loss of 0.480777), and 6 iterative models by use of scaled data and tuning various parameters of the models. Improvement is noted on using scaled data (log loss of 0.433117), and further slight improvements noted upon increasing regularization by decreasing 'C' (log loss of 0.433088) and changing the solver to 'saga' from the default 'lbfgs' (log loss of 0.433054). \n",
    "\n",
    "Therefore, the best logistic model found, with a log loss of 0.433054, uses scaled data, increased regularization and makes use of 'saga' solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Decision Tree Modelling\n",
    "\n",
    "The second model type we will create in aiming to help the client, ABC Bank predict customer turnover is Decision Tree. Just as previously, we will commence with a baseline model and then several iterations to tune the hyperparametrs of the model in the quest for a best performing estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.1 Build a Baseline Decision Tree Model**\n",
    "\n",
    "We start by establishing a baseline Decision Tree model that makes use of the preprocessed data before scaling, since this is not a distance based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.698924363915424"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Baseline Decision Tree model\n",
    "dt_baseline_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Use cross_val_score with scoring=\"neg_log_loss\" to evaluate the model on the unscaled training data\n",
    "dt_baseline_log_loss = cross_val_score(dt_baseline_model,\n",
    "                                           X_train_full,\n",
    "                                           y_train,\n",
    "                                           scoring=\"neg_log_loss\")\n",
    "\n",
    "dt_baseline_log_loss = -(dt_baseline_log_loss.mean())\n",
    "\n",
    "dt_baseline_log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of performance of Decision Tree baseline model**\n",
    "\n",
    "The Decision tree baseline model has a log loss of approximately 7.7. This model performs worse than all the logistic regression models which had log loss ranging from approx 0.433 to 0.575. This performance is almost similar -indeed slightly worse- to a 'dummy' model that would predict the majority class all the time (class 0) as it would have a log loss of 7.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.2 Build iterative Decision Tree Models**\n",
    "\n",
    "Judging by the poor performance of the baseline Decision Tree model, it may be overfitting and thus some pruning/ tuning is necessary. We will therefore tune iterative Decision Tree models, hoping to improve performance by reducing log loss. \n",
    "\n",
    "For Decision trees modelling, we shall employ a different strategy to find a best model.This will comprise of first finding an optimal value of a hyperparameter from a range of values, using ROC curves and AUC to investigate the optimum. 3 key hyperparameters shall be investigated i.e. max_depth, min_samples_splits and min_samples_leafs. After finding an optimum parameter value, we shall create a model varying only that one parameter from the baseline and evaluate it's log loss. At the end, we shall build a final Decision Tree model using all 3 optimum hyperparameter values, provided they improved the logloss during the individual iterative model investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.2.1 1st iterative Decision Tree  model - optimum max_depth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for iterative model 1, we vary the max_depth of the tree\n",
    "# we begin by finding the optimal value of max_depth\n",
    "\n",
    "max_depths = list(range(1, 33))\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_depth in max_depths:\n",
    "    dt_1st = DecisionTreeClassifier(random_state=42, max_depth=max_depth)\n",
    "    dt_1st.fit(X_train_full, y_train)\n",
    "    train_pred = dt_1st.predict(X_train_full)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    # Add auc score to previous train results\n",
    "    train_results.append(roc_auc)\n",
    "    y_pred = dt_1st.predict(X_test_full)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    # Add auc score to previous test results\n",
    "    test_results.append(roc_auc)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(max_depths, train_results, 'b', label='Train AUC')\n",
    "plt.plot(max_depths, test_results, 'r', label='Test AUC')\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A max_depth of around **6** seems to be optimal, we use this for building and evaluating the 1st iterative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49068518648119086"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterative model 1 with max_depth=6 as the only change from baseline model\n",
    "\n",
    "# Instantiate the Decision Tree model\n",
    "dt_model_1st_iteration = DecisionTreeClassifier(random_state=42, max_depth=6)\n",
    "\n",
    "# Use cross_val_score with scoring=\"neg_log_loss\" to evaluate the model on the unscaled training data\n",
    "dt_1st_iter_log_loss = cross_val_score(dt_model_1st_iteration,\n",
    "                                           X_train_full,\n",
    "                                           y_train,\n",
    "                                           scoring=\"neg_log_loss\")\n",
    "\n",
    "dt_1st_iter_log_loss = -(dt_1st_iter_log_loss.mean())\n",
    "\n",
    "dt_1st_iter_log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of performance of 1st iteration of Decision Tree model; max_depth=6** \n",
    "\n",
    "This 1st Decision Tree iteration performs much better (log loss of 0.49) than the baseline (log loss of 7.7). It is within range of the logistic regression models that ranged from 0.433 to 0.575."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.2.2  2nd iterative Decision Tree  model - optimum min_samples_splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for iterative model 2, we vary the min_samples_splits of the tree\n",
    "# we begin by finding the optimal value of min_samples_splits \n",
    "\n",
    "min_samples_splits = np.arange(10, 101)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_split in min_samples_splits:\n",
    "    dt_2nd = DecisionTreeClassifier(min_samples_split=min_samples_split, random_state=42)\n",
    "    dt_2nd.fit(X_train_full, y_train)\n",
    "    train_pred = dt_2nd.predict(X_train_full)\n",
    "    false_positive_rate, true_positive_rate, thresholds =    roc_curve(y_train, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_results.append(roc_auc)\n",
    "    y_pred = dt_2nd.predict(X_test_full)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_results.append(roc_auc)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(min_samples_splits, train_results, 'b', label='Train AUC')\n",
    "plt.plot(min_samples_splits, test_results, 'r', label='Test AUC')\n",
    "plt.xlabel('Min. Sample splits')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A min_samples_split of around **91** seems to be optimal, we use this for building and evaluating the 2nd iterative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9468049987982836"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterative model 2 with min_samples_split=91 as the only change from baseline model\n",
    "\n",
    "# Instantiate the Decision Tree model\n",
    "dt_model_2nd_iteration = DecisionTreeClassifier(random_state=42, min_samples_split=91)\n",
    "\n",
    "# Use cross_val_score with scoring=\"neg_log_loss\" to evaluate the model on the unscaled training data\n",
    "dt_2nd_iter_log_loss = cross_val_score(dt_model_2nd_iteration,\n",
    "                                           X_train_full,\n",
    "                                           y_train,\n",
    "                                           scoring=\"neg_log_loss\")\n",
    "\n",
    "dt_2nd_iter_log_loss = -(dt_2nd_iter_log_loss.mean())\n",
    "\n",
    "dt_2nd_iter_log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of performance of 2nd iteration of Decision Tree model; min_samples_split=91** \n",
    "\n",
    "This 2nd Decision Tree iteration, where we only change the min_samples_split, also performs better (log loss of 0.94) than the baseline model(log loss of 7.7). It is however slightly worse than both the 1st decision tree iteration model with change on max_depth (log loss of 0.49) and the logistic regression models (log loss of 0.433 to 0.575)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.2.3  3rd iterative Decision Tree  model - optimum min_samples_leaf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for iterative model 3, we vary the min_samples_leaf of the tree\n",
    "# we begin by finding the optimal value of min_samples_leaf\n",
    "\n",
    "min_samples_leafs = np.arange(1, 20)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_leaf in min_samples_leafs:\n",
    "    dt_3rd = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf, random_state=42)\n",
    "    dt_3rd.fit(X_train_full, y_train)\n",
    "    train_pred = dt_3rd.predict(X_train_full)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_results.append(roc_auc)\n",
    "    y_pred = dt_3rd.predict(X_test_full)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_results.append(roc_auc)\n",
    "\n",
    "plt.figure(figsize=(12,6))    \n",
    "plt.plot(min_samples_leafs, train_results, 'b', label='Train AUC')\n",
    "plt.plot(min_samples_leafs, test_results, 'r', label='Test AUC')\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Min. Sample Leafs')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A min_sample_leafs of around **16** seems to be optimal,  we use this for building and evaluating the 3rd iterative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3306273228242476"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterative model 3 with min_samples_leaf=16 as the only change from baseline model\n",
    "\n",
    "# Instantiate the Decision Tree model\n",
    "dt_model_3rd_iteration = DecisionTreeClassifier(random_state=42, min_samples_leaf=16)\n",
    "\n",
    "# Use cross_val_score with scoring=\"neg_log_loss\" to evaluate the model on the unscaled training data\n",
    "dt_3rd_iter_log_loss = cross_val_score(dt_model_3rd_iteration,\n",
    "                                           X_train_full,\n",
    "                                           y_train,\n",
    "                                           scoring=\"neg_log_loss\")\n",
    "\n",
    "dt_3rd_iter_log_loss = -(dt_3rd_iter_log_loss.mean())\n",
    "\n",
    "dt_3rd_iter_log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of performance of 3rd iteration of Decision Tree model; min_samples_leaf=16** \n",
    "\n",
    "This 3rd Decision Tree iteration, where we only vary the min_samples_leaf, also performs better (log loss of 1.33) than the baseline (log loss of 7.7). However, it doesn't do as well in reducing the log loss as the previous decision tree iterations (with change in max_depth and min_samples_split and the earlier logistic regression models (log loss of 0.433 to 0.575)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.2.4   4th iterative Decision Tree  model - vary all three parameters i.e. max_depth, min_samples_split and min_samples_leaf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4056777987939791"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterative model 4 with max_depth=6, min_samples_split=91 and min_samples_leaf=16\n",
    "\n",
    "# Instantiate the Decision Tree model\n",
    "dt_model_4th_iteration = DecisionTreeClassifier(random_state=42,\n",
    "                                                max_depth=6,\n",
    "                                                min_samples_split=91,\n",
    "                                                min_samples_leaf=16)\n",
    "\n",
    "# Use cross_val_score with scoring=\"neg_log_loss\" to evaluate the model on the unscaled training data\n",
    "dt_4th_iter_log_loss = cross_val_score(dt_model_4th_iteration,\n",
    "                                           X_train_full,\n",
    "                                           y_train,\n",
    "                                           scoring=\"neg_log_loss\")\n",
    "\n",
    "dt_4th_iter_log_loss = -(dt_4th_iter_log_loss.mean())\n",
    "\n",
    "dt_4th_iter_log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of performance of 4th iteration of Decision Tree model; varying all three parameters i.e. max_depth, min_samples_split and min_samples_leaf** \n",
    "\n",
    "This final Decision Tree iteration, where we vary all three parameters using the optimum values we found in the previous iterations, produces a log loss of approx 0.406. This is the lowest logloss so far and therefore this is the best performing model so far for the decision trees as it's lower than the baseline decision tree log loss of 7.7 and the decision tree iterations models (with log loss of 0.49 to 1.33). This model also outperforms the earlier logistic regression models (with log loss of 0.433 to 0.575)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.3 Summary on Decision Tree Modelling**\n",
    "\n",
    "We built a baseline  Decision Tree model with no tuning/pruning with a resultant log loss of 7.7; and 3 iterative models where we tuned different hyperparameters with resultant log loss of 0.49 to 1.33 and a final Decision Tree model with all hyperparameters of previous iterations. This final model is \n",
    "therefore, the best model found so far with a log loss of 0.406. It is the best of the Decision Tree and Logistic regression models. This model has a max_depth=6, min_samples_split=91 and            min_samples_leaf=16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Random Forest Modelling\n",
    "\n",
    "The third and final model type we will look into to provide ABC Bank with an optimal solution is Random Forest. Just as before, we will commence with a baseline model and then create iterative models to tune the hyperparameters of the model to hopefully get an even better performing model.\n",
    "\n",
    "GridSearchCV will be utilised this time round, in tuning the Random Forest model, unlike in the Logistic regression model where we kept varying parameters 'manually' i.e. one by one and unlike the Decision tree model tuning where we tried to get optimal parameters from a range of values individually for each parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3.1 Build a Baseline Random Forest Model**\n",
    "\n",
    "We start by establishing a baseline Random Forest model that makes use of the preprocessed data before scaling, since this is a tree based model which does not require data scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3805422560660256"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Random Forest model with default parameters\n",
    "forest_baseline_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Use cross_val_score with scoring=\"neg_log_loss\" to evaluate the model on the unscaled training data\n",
    "forest_baseline_log_loss = cross_val_score(forest_baseline_model,\n",
    "                                           X_train_full,\n",
    "                                           y_train,\n",
    "                                           scoring=\"neg_log_loss\")\n",
    "\n",
    "forest_baseline_log_loss = -(forest_baseline_log_loss.mean())\n",
    "\n",
    "forest_baseline_log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of baseline Random Forest model** \n",
    "\n",
    "The baseline Random Forest model with default parameters results in a log loss of 0.38. This is the best performing model so far compared to all the Logistic Regression Models (with log loss ranging from 0.433 to 0.575) and all the Decision Tree models (with log loss ranging from 0.406 to 7.7). Nonetheless, we would like to tune the model for even better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3.2 Using GridSearchCV Identify optimal Random Forest Models**\n",
    "\n",
    "Despite the Baseline Random Forest model producing the best log loss i.e. the lowest so far, we shall perform a hyperparameter tuning exercise to see if we can produce an even better model. \n",
    "\n",
    "For this exercise, we make use of GridSearchCV a combinatorial grid search to find an optimal combination of parameters for the baseline Random Forest model; unlike in the previous model types, where we tuned the parameters gradually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter grid with different values; \n",
    "# choice of values will be guided by those used to tune the previous decision tree estimators\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 30, 100],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [None, 5, 6, 9],\n",
    "    \"min_samples_split\": [91, 115],\n",
    "    \"min_samples_leaf\": [16, 18],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Parameters: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 16, 'min_samples_split': 91, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate GridSearchCV\n",
    "grid_search = GridSearchCV(forest_baseline_model, param_grid)\n",
    "grid_search.fit(X_train_full, y_train)\n",
    "\n",
    "print(f\"Optimal Parameters: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the optimal parameters from GridSearchCV to build the optimal Random Forest model and assess its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36447661039969464"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the iterative Random forest model with optimal parameters from GridSearchCV\n",
    "forest_iterative_model = RandomForestClassifier(random_state=42,\n",
    "                                                criterion='entropy',\n",
    "                                                max_depth=9,\n",
    "                                                min_samples_leaf=16,\n",
    "                                                min_samples_split=91,\n",
    "                                                n_estimators=100)\n",
    "\n",
    "# Use cross_val_score with scoring=\"neg_log_loss\" to evaluate the model on the unscaled training data\n",
    "forest_iterative_log_loss = cross_val_score(forest_iterative_model,\n",
    "                                           X_train_full,\n",
    "                                           y_train,\n",
    "                                           scoring=\"neg_log_loss\")\n",
    "\n",
    "forest_iterative_log_loss = -(forest_iterative_log_loss.mean())\n",
    "\n",
    "forest_iterative_log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of Iterative Random Forest Models using GridSearchCV optimal parameters** \n",
    "\n",
    "The iterated Random Forest model tuned with hyperparameters resulting from GridSearchCV produces a log loss of 0.36, which is an improvement to the baseline Random Forest that uses default parameters with log loss of 0.38. This is the best performing model so far compared to all the previous Logistic Regression Models (with log loss ranging from 0.433 to 0.575) and all the Decision Tree models (with log loss ranging from 0.406 to 7.7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3.3 Feature Importance**\n",
    "\n",
    "We also investigate and visualize how important each feature is to the Random Forest models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAHgCAYAAABHMnwXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAv/klEQVR4nO3defhdZX33+/fHgGEOIpETURu0AYqAQQKKUEWLnlqsYEXRWgvFp9EWnHqopRcOOLWxeioKVYw+iLZqKQiK0jKIBh+ZE4aEgDgRHxs5RxGMyCjh+/yxV2T78zfs5Dcld96v69rXXnutdd/ru5Y/w+e677X3SlUhSZLUmsdMdwGSJEmTwZAjSZKaZMiRJElNMuRIkqQmGXIkSVKTDDmSJKlJW0x3AZpYO++8c82dO3e6y5AkaUosW7bszqqaPdw2Q05j5s6dy9KlS6e7DEmSpkSSH460zekqSZLUJEOOJElqkiFHkiQ1yZAjSZKaZMiRJElNMuRIkqQmGXIkSVKTDDmSJKlJhhxJktQkQ44kSWqSIUeSJDXJkCNJkppkyJEkSU0y5EiSpCYZciRJUpMMOZIkqUmGHEmS1CRDjiRJatIW012AJtaK1WuYe9KF4+pj1aLDJ6gaSZKmjyM5kiSpSYYcSZLUJEOOJElqkiFHkiQ1yZAjSZKaZMiRJElNMuRIkqQmGXImSZJK8q99n7dI8tMkXx2j3aFj7SNJksZmyJk89wJ7J9m6+/xCYPU01iNJ0mbFkDO5/gtY9/PBrwa+sG5DkgOTXJnkhu59j6GNk2yb5Mwk13X7HTFFdUuStMkz5EyufwdelWQrYF/gmr5t3waeW1X7Ae8E/mGY9icDX6+qA4DnAx9Msu0k1yxJUhN8dtUkqqrlSebSG8X5zyGbZwGfSTIPKGDLYbp4EfDSJCd2n7cCngLc2r9TkoXAQoAZO8yesPolSdqUGXIm3wXAh4BDgcf3rX8v8I2qelkXhJYM0zbAy6vqttEOUFWLgcUAM+fMq/GXLEnSps/pqsl3JvCeqloxZP0sHr0R+dgR2l4MvDFJAJLsNykVSpLUIEPOJKuq/66qjwyz6Z+Af0xyBTBjhObvpTeNtTzJzd1nSZI0AKerJklVbTfMuiV001JVdRWwe9/mdwyzz/3A6ye1UEmSGuVIjiRJapIhR5IkNcmQI0mSmmTIkSRJTTLkSJKkJhlyJElSkww5kiSpSf5OTmP22XUWSxcdPvaOkiQ1zpEcSZLUJEOOJElqkiFHkiQ1yZAjSZKaZMiRJElNMuRIkqQm+RXyxqxYvYa5J104rj5W+RV0SVIDHMmRJElNMuRIkqQmGXIkSVKTDDmSJKlJhhxJktQkQ44kSWqSIUeSJDXJkDOAJGuT3Nj3mjuJx1qVZOfJ6l+SpM2FPwY4mPurav50FyFJkgbnSM4GSrJ/ksuTLEtycZI53folST6c5JtJbk1yQJLzknw3yfv62n+pa7syycIRjvFnSa7tRo8+kWTGVJ2fJEmbOkPOYLbum6o6P8mWwGnAUVW1P3Am8P6+/R+qqucCZwBfBo4H9gaOTfL4bp/jurYLgDf1rQcgye8BRwMHd6NIa4HXTN4pSpLUFqerBvMb01VJ9qYXWi5NAjADuKNv/wu69xXAyqq6o2v3A+DJwM/oBZuXdfs9GZjXrV/nD4D9geu6Y2wN/GS44rqRoIUAM3aYvaHnKElSUww5Gyb0wstBI2x/sHt/pG953ectkhwKHAYcVFX3JVkCbDXMMT5TVX8/VjFVtRhYDDBzzrwa8BwkSWqa01Ub5jZgdpKDAJJsmeTp69F+FnB3F3D2BJ49zD6XAUcleUJ3jJ2S/M54C5ckaXNhyNkAVfUQcBTwgSQ3ATcCz1mPLi6iN6KzHHgvcPUwx7gFeDtwSbffpcCccZYuSdJmI1XObrRk5px5NeeYU8fVx6pFh09MMZIkTbIky6pqwXDbHMmRJElNMuRIkqQmGXIkSVKTDDmSJKlJhhxJktQkQ44kSWqSIUeSJDXJxzo0Zp9dZ7HU37mRJMmRHEmS1CZDjiRJapIhR5IkNcmQI0mSmmTIkSRJTfLbVY1ZsXoNc0+6cFx9+BRySVILHMmRJElNMuRIkqQmGXIkSVKTDDmSJKlJhhxJktQkQ44kSWqSIUeSJDXJkCNJkppkyJkgSU5OsjLJ8iQ3JnnWBvTx0iQnTUZ9kiRtbvzF4wmQ5CDgJcAzq+rBJDsDj13ffqrqAuCCia5PkqTNkSM5E2MOcGdVPQhQVXdW1Y+TrErygSTXdq/fBUjyx0muSXJDkq8l2aVbf2yS07vls5J8NMmVSX6Q5KhpOztJkjZBhpyJcQnw5CTfSfKxJM/r2/aLqjoQOB04tVv3LeDZVbUf8O/A20bodw5wCL1RokWTUrkkSY1yumoCVNUvk+wP/D7wfODsvntrvtD3/uFu+UndPnPoTWvdPkLXX6qqR4Bb1o32DCfJQmAhwIwdZo/rXCRJaoUjOROkqtZW1ZKqehdwAvDydZv6d+veTwNOr6p9gNcDW43Q7YN9yxnl2IurakFVLZixzawNOwFJkhpjyJkASfZIMq9v1Xzgh93y0X3vV3XLs4DV3fIxk16gJEmbIaerJsZ2wGlJdgQeBr5Hb/roJcDMJNfQC5Sv7vY/BTgnyWrgamC3qS5YkqTWparG3ksbJMkqYEFV3TlVx5w5Z17NOebUcfWxatHhE1OMJEmTLMmyqlow3DanqyRJUpOcrppEVTV3umuQJGlz5UiOJElqkiFHkiQ1yZAjSZKaZMiRJElNMuRIkqQm+e2qxuyz6yyW+js3kiQ5kiNJktpkyJEkSU0y5EiSpCYZciRJUpMMOZIkqUl+u6oxK1avYe5JF053Gb/FJ5tLkqaaIzmSJKlJhhxJktQkQ44kSWqSIUeSJDXJkCNJkppkyJEkSU0y5EiSpCYZciRJUpM2+5CTZJckn0/ygyTLklyV5GXTXZckSRqfzTrkJAnwJeCbVfXUqtofeBXwpAHbz5jE8iRJ0jhs1iEHeAHwUFWdsW5FVf2wqk5LMiPJB5Ncl2R5ktcDJDk0yTeSfB5Y0X2+PMl/JPlOkkVJXpPk2iQrkjyta/fHSa5JckOSryXZpVt/SpIzkyzpRpPe1K1/b5I3r6sryfvXbZMkSWPb3EPO04HrR9j2OmBNVR0AHAD8ZZLdum0HAidX1V7d52cAbwb2AV4L7F5VBwKfAt7Y7fMt4NlVtR/w78Db+o61J/B/d/2+K8mWwP8EjgFI8hh6I0yfG9/pSpK0+fABnX2S/AtwCPAQ8ENg3yRHdZtnAfO6bddW1e19Ta+rqju6Pr4PXNKtXwE8v1t+EnB2kjnAY4H+9hdW1YPAg0l+AuxSVauS/CzJfsAuwA1V9bMR6l4ILASYscPsDb8AkiQ1ZHMfyVkJPHPdh6o6HvgDYDYQ4I1VNb977VZV68LLvUP6ebBv+ZG+z4/waJA8DTi9qvYBXg9sNUL7tX1tPgUcC/wFcOZIJ1FVi6tqQVUtmLHNrFFOV5KkzcfmHnK+DmyV5K/61m3TvV8M/FU3dUSS3ZNsO45jzQJWd8vHDNjmfOAP6U2XXTyOY0uStNnZrKerqqqSHAl8OMnbgJ/SG6X5O+AcYC5wffctrJ8CR47jcKcA5yRZDVwN7Db67lBVDyX5BvDzqlo7jmNLkrTZSVVNdw0aQXfD8fXAK6rqu4O0mTlnXs055tRJrWtDrFp0+HSXIElqUJJlVbVguG2b+3TVRivJXsD3gMsGDTiSJOlRm/V01casqm4BnjrddUiStKlyJEeSJDXJkCNJkppkyJEkSU0y5EiSpCYZciRJUpP8dlVj9tl1Fkv9TRpJkhzJkSRJbTLkSJKkJhlyJElSkww5kiSpSYYcSZLUJL9d1ZgVq9cw96QLx92PTw2XJG3qHMmRJElNMuRIkqQmGXIkSVKTDDmSJKlJhhxJktQkQ44kSWqSIUeSJDXJkCNJkprkjwGupyRrgRV9q46sqlXTVI4kSRqBIWf93V9V84fbkCRAquqRqS1JkiQN5XTVOCWZm+TWJB8DrgeenOTjSZYmWZnk3X37rkry7iTXJ1mRZM9u/XZJPt2tW57k5d36FyW5qtv/nCTbTc9ZSpK06THkrL+tk9zYvc7v1u0BfLaq9quqHwInV9UCYF/geUn27Wt/Z1U9E/g4cGK37h3Amqrap6r2Bb6eZGfg7cBh3f5Lgb+ZgvOTJKkJTletv9+YrkoyF/hhVV3dt88rkyykd33nAHsBy7tt53Xvy4A/6ZYPA161rnFV3Z3kJV27K3qzYDwWuGq4grpjLQSYscPscZyaJEntMORMjHvXLSTZjd4IzQFdWDkL2Kpv3we797U8ev0D1JA+A1xaVa8e6+BVtRhYDDBzzryh/UiStFlyumri7UAv9KxJsgvw4gHaXAKcsO5DkscBVwMHJ/ndbt02SXafhHolSWqSIWeCVdVNwA3ASuBM4IoBmr0PeFySm5PcBDy/qn4KHAt8IclyeqFnz8mpWpKk9jhdtZ6qarshn1cBew9Zd+wIbef2LS8FDu2WfwkcM8z+XwcOGF/FkiRtnhzJkSRJTTLkSJKkJhlyJElSkww5kiSpSYYcSZLUJEOOJElqkiFHkiQ1yd/Jacw+u85i6aLDp7sMSZKmnSM5kiSpSYYcSZLUJEOOJElqkiFHkiQ1yZAjSZKa5LerGrNi9RrmnnThdJchaSO0ym9eajPjSI4kSWqSIUeSJDXJkCNJkppkyJEkSU0y5EiSpCYZciRJUpMMOZIkqUmGHEmS1CRDjiRJatJGE3KSHJvkiX2fP5Vkrwnod26SP92AdmclOWq8x+/6OjbJ6RPRlyRJGsxGE3KAY4Ffh5yq+h9VdcsE9DsXWO+QM52S+LgNSZLGadJDTpI/S3JtkhuTfCLJjG6U5OYkK5K8tRsxWQB8rttv6yRLkizo+vhlkg8kWZbka0kO7Lb/IMlLu33mJvlfSa7vXs/pSlgE/H7X71u7438wyXVJlid5fdc+SU5PckuSC4EnjHFei7p9lyf5ULfuj5Nck+SGrs5dhmk37D5JTkmyOMklwGe7c5nf1+6KJPuOUMvCJEuTLF1735r1+t9HkqRWTeqIQZLfA44GDq6qXyX5GPB2YNeq2rvbZ8eq+nmSE4ATq2ppt76/q22BJVX1d0nOB94HvBDYC/gMcAHwE+CFVfVAknnAF+gFp5O6fl/S9bsQWFNVBySZCVzRBYv9gD2AfYBdgFuAM0c4r52AlwF7VlUl2bHb9C3g2d26/wG8Dfh/hjQfbZ/9gUOq6v4kx9Ab3XpLkt2BmVW1fLh6qmoxsBhg5px5Ndw+kiRtbiZ7WuQP6P2H+7outGwNXAQ8NclpwIXAJQP081DXDmAF8GAXmlbQm44C2BI4vRv9WAvsPkJfLwL27bvfZhYwD3gu8IWqWgv8OMnXR6nnF8ADwKe6UZ+vduufBJydZA7wWOD2YdqOts8FVXV/t3wO8I4kfwscB5w1Sj2SJGmIyZ6uCvCZqprfvfaoqjcDzwCWAMcDnxqgn19V1boRikeABwGq6hEeDWpvBf7/ru8F9ALESDW9sa+m3apqXdAaaBSkqh4GDgS+CBzJowHsNOD0qtoHeD2w1TDNR9vn3r5j3AdcChwBvBL4/CC1SZKknskOOZcBRyV5AvSmeZL8DvCYqvoi8A7gmd2+9wDbj+NYs4A7uuDzWmDGCP1eDPxVki27mnZPsi3wTeBV3T07c4Dnj3SgJNsBs6rqP4G3APP7aljdLR8zSp1j7bPOp4CPAtdV1V1j7CtJkvpM6nRVVd2S5O3AJUkeA/wK+Bvg/O4zwN9372cBZyS5HzhoAw73MeCLSV4BfINHR0WWAw8nuak7xkfoTXFdn94c2k/pjcacD7yA3nTYd4DLRznW9sCXk2xFb2Tord36U4BzkqwGrgZ2G6btIPsAUFXLkvwC+PQotUiSpGHk0VkgbWy63w1aQu8G50cGaTNzzryac8ypk1mWpE3UqkWHT3cJ0oRLsqyqFgy3bWP6nRz1SfLnwDXAyYMGHEmS9Ch/dG4M3VfWh04p/V1VXTyZx62qzwKfncxjSJLUMkPOGKrqZdNdgyRJWn9OV0mSpCYZciRJUpMMOZIkqUnek9OYfXadxVK/JipJkiM5kiSpTQOHnCRbJ9ljMouRJEmaKAOFnCR/DNxI9yDKJPOTXDCJdUmSJI3LoCM5p9B76vbPAarqRnrPf5IkSdooDRpyHq6qNZNaiSRJ0gQa9NtVNyf5U2BGknnAm4ArJ68sbagVq9cw96QLp7uMjYIPI5SkzdugIzlvBJ4OPAh8HlgDvGWSapIkSRq3MUdykswALqiqw4CTJ78kSZKk8RtzJKeq1gL3JZk1BfVIkiRNiEHvyXkAWJHkUuDedSur6k2TUpUkSdI4DRpyLuxekiRJm4SBQk5VfWayC5EkSZpIA4WcJLcDNXR9VT11wiuSJEmaAINOVy3oW94KeAWw08SXI0mSNDEG+p2cqvpZ32t1VZ0KvGByS5MkSdpwg05XPbPv42PojexsPykVjV7HocBDVXVl9/kNwH1V9dmprmVDJTkWWFBVJ0x3LZIktWzQ6ar/t2/5YeB24JUTX86YDgV+SfdIiao6YxpqmFZJZnS/XSRJkkYx6GMdXldVz+9eL6yqhcBDE1VEki8lWZZkZZKF3bo/THJ9kpuSXJZkLvAG4K1Jbkzy+0lOSXJikt9Lcm1ff3OTLO+W909yedf/xUnmjFLHkiQfTvLNJLcmOSDJeUm+m+R9ffv9WZJruzo+0f0qNEl+meQD3bG+luTArs8fJHlp36GenOSiJLcledeA/b4nyTXAQcPUvTDJ0iRL197nc1QlSYLBQ865A67bUMdV1f70psHelGQX4JPAy6vqGcArqmoVcAbw4aqaX1X/a13jqroVeGySdd/2Ohr4jyRbAqcBR3X9nwm8f4xaHqqq53bH+jJwPLA3cGySxyf5va7/g6tqPrAWeE3XdltgSXese4D3AS8EXga8p+8YB3Zt5gOvSLJggH5vrqpnVdW3hhZcVYurakFVLZixjT9MLUkSjDFdlWRPeg/mnJXkT/o27UDvW1YT5U1JXtYtPxlYCHyzqm4HqKq7BujjP+hNoS2iFxaOBvagF1AuTQIwA7hjjH4u6N5XACur6g6AJD/oajsE2B+4rutza+AnXZuHgIv62j9YVb9KsgKY23eMS6vqZ12/53V9PjxKv2uBLw5wDSRJUmese3L2AF4C7Aj8cd/6e4C/nIgCupuJDwMOqqr7kiwBbuqOvT7OBs7pQkNV1XeT7EMvqPzWFM8oHuzeH+lbXvd5CyDAZ6rq74dp+6uqqr79H6RXzCNJ+q/10N8cqjH6fcD7cCRJWj+jhpyq+jLw5SQHVdVVk1TDLODuLuDsCTwbmAk8L8luVXV7kp260Zx76I0iDVfr95OsBd5BL/AA3AbMXld/N321e1WtHEe9l9G7Jh+uqp8k2QnYvqp+uB59vLBrdz9wJHAccN8E9CtJkjqDfrvqhiTH05u6+vU0VVUdNwE1XAS8obtR+DbgauCn9KaszkvyGHrTNi8EvgKcm+QI4I3D9HU28EFgt66+h5IcBXy0e4r6FsCpwAaHnKq6JcnbgUu62n5F776d9Qkj3wL+Ffhd4PNVtRRgAvqVJEmdPDq7MspOyTnAt4E/pXcD7WuAW6vqzZNbntbXzDnzas4xp053GRuFVYsOn+4SJEmTLMmyqlow3LZBv131u1X1DuDe7mGdhwP7TFSBkiRJE23Q6apfde8/T7I38P/xm98W2qQk+Rfg4CGrP1JVn56OeiRJ0sQbNOQsTvI4ejf1XgBsB7xz0qqaZFV1/HTXIEmSJtdAIaeqPtUtXg48dbR9JUmSNgYD3ZOTZJck/zPJf3Wf90ryusktTZIkacMNeuPxWcDFwBO7z98B3jIJ9UiSJE2IQe/J2bmq/iPJ3wNU1cPdD+9pI7PPrrNY6lenJUkaeCTn3iSPp3scQZJnAz7uWpIkbbQGHcn5G3rfqnpakiuA2cBRk1aVJEnSOI31FPKnVNX/rqrrkzyP3kMzA9xWVb8ara0kSdJ0Gmu66kt9y2dX1cqqutmAI0mSNnZjhZz0Lfv7OJIkaZMx1j05NcKyNlIrVq9h7kkXTncZgA/IlCRNr7FCzjOS/ILeiM7W3TLd56qqHSa1OkmSpA00asipqhlTVYgkSdJEGvR3ciRJkjYphhxJktQkQ44kSWqSIUeSJDXJkCNJkppkyJEkSU0y5IwhyS+79ycmObdbnp/kj6awhkOTfHWqjidJUgs2y5CTZNCnr/9aVf24qtY9eX0+MGkhJ4m/TyRJ0jit93/sNxVJ/hw4kd7jKJYDa4G7gP2A65N8DPgXYDZwH/CXVfXtJLsBn6d3bS7q628u8FXgmcB76P0C9CHAP1bV2cMcfzvgNGBBV8O7q+qLST4OHABsDZxbVe/q9l8FnAm8CDg9yc+BU4E7gesn6rpIkrS5aDLkJHk6cDJwcFXdmWQn4J+B3YHDqmptksuAN1TVd5M8C/gY8ALgI8DHq+qzSY4f2ndVPZTkncCCqjphlDLeAaypqn26mh7XrT+5qu7qRmsuS7JvVS3vtj1QVYck2Qr4blfP94DfClFDznchsBBgxg6zx7w+kiRtDlqdrnoBvVGSOwGq6q5u/TldwNkOeA5wTpIbgU8Ac7p9Dga+0C3/6zhqOIzeSBFdDXd3i69Mcj1wA/B0YK++NuvCzJ7A7VX13aoq4N9GO1BVLa6qBVW1YMY2s8ZRsiRJ7WhyJIfuAaLDrL+3e38M8POqmj9C+4l44vpv1dBNhZ0IHFBVdyc5C9hqmPomqgZJkjZbrY7kXEZvxOTxAN101a9V1S+A25O8otueJM/oNl8BvKpbfs0I/d8DbD9GDZcAv57O6qardqAXZNYk2QV48Qhtvw3sluRp3edXj3EsSZI0RJMhp6pWAu8HLk9yE737cYZ6DfC6bvtK4Ihu/ZuB45NcB4w09/MNYK8kNyY5eoR93gc8LsnN3TGeX1U30ZumWknvJuMrRqj/AXr32FyY5FvAD0c/Y0mSNFR6t3yoFTPnzKs5x5w63WUAsGrR4dNdgiSpcUmWVdWC4bY1OZIjSZLU6o3HUybJX9Cb4up3RVX91tfPJUnS1DHkjFNVfRr49HTXIUmSfpPTVZIkqUmGHEmS1CRDjiRJapIhR5IkNckbjxuzz66zWOrv00iS5EiOJElqkyFHkiQ1yZAjSZKaZMiRJElNMuRIkqQm+e2qxqxYvYa5J1043WVIGmKV33qUppwjOZIkqUmGHEmS1CRDjiRJapIhR5IkNcmQI0mSmmTIkSRJTTLkSJKkJhlyJElSkzaJkJPk2CSnj6PtEye6pg2V5NAkX53uOiRJat20hpwkM6bgMMcCG03IGa8pumaSJG3yJi3kJJmb5NtJPpNkeZJzk2yTZFWSdyb5FvCKJK9OsiLJzUk+0Nf+L5J8J8nlwMF9689KclTf51/2Lb+t6+umJIu6/RYAn0tyY5Ktu/W3dDV9aJT6z0ry0SRXJvnBumMOHYlJcnqSY7vlVUn+IclVSZYmeWaSi5N8P8kb+rrfIcn5XR1nJHlM1/5FXdvrk5yTZLu+fn99zTbwfxJJkjYrk/3sqj2A11XVFUnOBP66W/9AVR3STSNdDewP3A1ckuRI4Brg3d36NcA3gBtGO1CSFwNHAs+qqvuS7FRVdyU5ATixqpYm2Ql4GbBnVVWSHceofw5wCLAncAFw7gDn/KOqOijJh4Gz6AW0rYCVwBndPgcCewE/BC4C/iTJEuDtwGFVdW+SvwP+BnhP1+aBqjpkhHNfCCwEmLHD7AFKlCSpfZMdcn5UVVd0y/8GvKlbPrt7PwBYUlU/BUjyOeC53bb+9WcDu49xrMOAT1fVfQBVddcw+/wCeAD4VJILgbHujflSVT0C3JJklzH2XeeC7n0FsF1V3QPck+SBvlB1bVX9ACDJF+gFqQfoBZ8rkgA8Friqr9+zGUFVLQYWA8ycM68GrFOSpKZNdsgZ+h/cdZ/v7d6zHm3XeZhumi29NPDYvr5G/Q98VT2c5EDgD4BXAScALxilyYN9y+tq/fXxO1uN0OaRIe0f4dHrPdx1CXBpVb16hFruHWG9JEkaxmTfePyUJAd1y68GvjVk+zXA85Ls3N1Q+2rg8m79oUken2RLfvM+lFX0prEAjgC27JYvAY5Lsg1ANzUFcA+wfbduO2BWVf0n8BZg/gac0w+BvZLMTDKLXmBaXwcm2a27F+doetflauDgJL/b1bpNkrFGryRJ0ggmO+TcChyTZDmwE/Dx/o1VdQfw9/TuubkJuL6qvtytP4XedM3XgOv7mn2SXjC6FngW3QhHVV1Eb6poaZIbgRO7/c8CzujWbQ98tavncuCt63tCVfUj4D+A5cDnGONeoRFcBSwCbgZuB87vpuaOBb7Q1Xc1vXuBJEnSBkjV5NzCkWQu8NWq2ntSDqBhzZwzr+Ycc+p0lyFpiFWLDp/uEqQmJVlWVQuG27ZJ/BigJEnS+pq0G4+rahWw0Y/iJDmZ3/7tmXOq6v3TUY8kSZoYk/3tqo1eF2YMNJIkNcbpKkmS1CRDjiRJapIhR5IkNWmzvyenNfvsOoulflVVkiRHciRJUpsMOZIkqUmGHEmS1CRDjiRJapIhR5IkNcmQI0mSmuRXyBuzYvUa5p504XSXIWkS+URzaTCO5EiSpCYZciRJUpMMOZIkqUmGHEmS1CRDjiRJapIhR5IkNcmQI0mSmmTIGUGSuUluXo/9z0py1GTWJEmSBmfIkSRJTTLkjG6LJJ9JsjzJuUm2SfLOJNcluTnJ4iQZ2mikfZIsSfKBJNcm+U6S3+/Wz0jyoSQrumO9sVu/f5LLkyxLcnGSOVN7+pIkbboMOaPbA1hcVfsCvwD+Gji9qg6oqr2BrYGXDNNutH22qKoDgbcA7+rWLQR2A/brjvW5JFsCpwFHVdX+wJnA+yf8DCVJapTPrhrdj6rqim7534A3AbcneRuwDbATsBL4ypB2zx9ln/O692XA3G75MOCMqnoYoKruSrI3sDdwaTcQNAO4Y7gikyykF5SYscPsDT1XSZKaYsgZXQ3z+WPAgqr6UZJTgK36d0iy1Rj7PNi9r+XR659hjhVgZVUdNGaRVYuBxQAz58wb2o8kSZslp6tG95Qk60LGq4Fvdct3JtkOGO7bVFsNsM9QlwBvSLIFQJKdgNuA2euOn2TLJE/fwPOQJGmz40jO6G4FjknyCeC7wMeBxwErgFXAdUMbVNXPk3xytH2G8Slgd2B5kl8Bn6yq07uvpH80ySx6/1udSm/qS5IkjSFVzm60ZOaceTXnmFOnuwxJk2jVosOnuwRpo5FkWVUtGG6b01WSJKlJhhxJktQkQ44kSWqSIUeSJDXJkCNJkppkyJEkSU0y5EiSpCb5Y4CN2WfXWSz1NzQkSXIkR5IktcmQI0mSmmTIkSRJTTLkSJKkJhlyJElSkww5kiSpSX6FvDErVq9h7kkXTncZatQqf55A0ibEkRxJktQkQ44kSWqSIUeSJDXJkCNJkppkyJEkSU0y5EiSpCYZciRJUpMMOespyY5J/nq665AkSaMz5Ky/HYFJDTlJ/JFGSZLGyZCz/hYBT0tyY5IPJvnbJNclWZ7k3QBJ5ia5Ncknk6xMckmSrbttS5Is6JZ3TrKqWz42yTlJvgJckmTbJGd2fd+Q5IhpOl9JkjZJhpz1dxLw/aqaD1wKzAMOBOYD+yd5brffPOBfqurpwM+Blw/Q90HAMVX1AuBk4OtVdQDwfOCDSbadwPOQJKlpTouMz4u61w3d5+3ohZv/DdxeVTd265cBcwfo79Kququv75cmObH7vBXwFODWoY2SLAQWAszYYfZ6n4QkSS0y5IxPgH+sqk/8xspkLvBg36q1wNbd8sM8OoK21ZD+7h3S98ur6raxiqiqxcBigJlz5tWgxUuS1DKnq9bfPcD23fLFwHFJtgNIsmuSJ4zRfhWwf7d81Cj7XQy8MUm6vvfb4IolSdoMGXLWU1X9DLgiyc3AC4HPA1clWQGcy6MBaCQfAv4qyZXAzqPs915gS2B5d6z3jrt4SZI2I6lydqMlM+fMqznHnDrdZahRqxYdPt0lSNJvSLKsqhYMt82RHEmS1CRDjiRJapIhR5IkNcmQI0mSmmTIkSRJTTLkSJKkJhlyJElSk3ysQ2P22XUWS/0tE0mSHMmRJEltMuRIkqQmGXIkSVKTDDmSJKlJhhxJktQkv13VmBWr1zD3pAunuwxJkn7Lqin+9q8jOZIkqUmGHEmS1CRDjiRJapIhR5IkNcmQI0mSmmTIkSRJTTLkSJKkJhlyJElSkww5kiSpSYYcSZLUJEPOFEvypSTLkqxMsrBb97ok30myJMknk5zerZ+d5ItJruteB09v9ZIkbTp8dtXUO66q7kqyNXBdkguBdwDPBO4Bvg7c1O37EeDDVfWtJE8BLgZ+bzqKliRpU2PImXpvSvKybvnJwGuBy6vqLoAk5wC7d9sPA/ZKsq7tDkm2r6p7+jvsRoQWAszYYfYkly9J0qbBkDOFkhxKL7gcVFX3JVkC3MbIozOP6fa9f7R+q2oxsBhg5px5NVH1SpK0KfOenKk1C7i7Czh7As8GtgGel+RxSbYAXt63/yXACes+JJk/lcVKkrQpM+RMrYuALZIsB94LXA2sBv4BuAb4GnALsKbb/03AgiTLk9wCvGHqS5YkadPkdNUUqqoHgRcPXZ9kaVUt7kZyzqc3gkNV3QkcPbVVSpLUBkdyNg6nJLkRuBm4HfjStFYjSVIDHMnZCFTVidNdgyRJrXEkR5IkNcmQI0mSmmTIkSRJTTLkSJKkJhlyJElSk/x2VWP22XUWSxcdPt1lSJI07RzJkSRJTTLkSJKkJhlyJElSkww5kiSpSYYcSZLUJL9d1ZgVq9cw96QLp7sMSRuJVX7bUpsxR3IkSVKTDDmSJKlJhhxJktQkQ44kSWqSIUeSJDXJkCNJkppkyJEkSU0y5EiSpCYZciRJUpMMOUMk+WX3/sQk53bL85P80fRWJkmS1sdmEXKSrPfjK6rqx1V1VPdxPjClIWdDapYkSY9q5j+kSf4cOBEoYDmwFrgL2A+4PsnHgH8BZgP3AX9ZVd9OshvweXrX4qK+/uYCXwWeCbwH2DrJIcA/VtXZwxz/ecBHuo8FPLeq7knyNuC1wCPAf1XVSUnmA2cA2wDfB46rqruTLAGuBA4GLug+/zOwHXAncGxV3TH+qyVJUvuaCDlJng6cDBxcVXcm2YleONgdOKyq1ia5DHhDVX03ybOAjwEvoBdMPl5Vn01y/NC+q+qhJO8EFlTVCaOUcSJwfFVdkWQ74IEkLwaOBJ5VVfd1dQF8FnhjVV2e5D3Au4C3dNt2rKrnJdkSuBw4oqp+muRo4P3AccOc/0JgIcCMHWYPetkkSWpaEyGHXlg5t6ruBKiqu5IAnNMFnO2A5wDndOsBZnbvBwMv75b/FfjABtZwBfDPST4HnFdV/53kMODTVXVfX12z6AWZy7t2nwHO6etn3SjRHsDewKVdzTOAYUdxqmoxsBhg5px5tYH1S5LUlFZCTuhNEQ11b/f+GODnVTV/hPbjDgZVtSjJhfTu3bm6Czgj1TWadTUHWFlVB423NkmSNket3Hh8GfDKJI8H6JsWAqCqfgHcnuQV3fYkeUa3+QrgVd3ya0bo/x5g+9EKSPK0qlpRVR8AlgJ7ApcAxyXZZl1dVbUGuDvJ73dNX0tvWmqo24DZSQ7q2m7ZTctJkqQBNBFyqmolvftVLk9yE737cYZ6DfC6bvtK4Ihu/ZuB45NcB8wa4RDfAPZKcmN3b8xw3pLk5q7/++ndZHwRcAGwNMmN9O7bATgG+GCS5fS+ufWeYc7pIeAo4ANdnzfSm3KTJEkDSJW3cLRk5px5NeeYU6e7DEkbiVWLDp/uEqRJlWRZVS0YblsTIzmSJElDtXLj8ZRJ8hf0prj6XVFVv/X1c0mSNH0MOeupqj4NfHq665AkSaNzukqSJDXJkCNJkppkyJEkSU3ynpzG7LPrLJb6lVFJkhzJkSRJbTLkSJKkJhlyJElSkww5kiSpSYYcSZLUJEOOJElqkiFHkiQ1yZAjSZKaZMiRJElNMuRIkqQmGXIkSVKTDDmSJKlJhhxJktQkQ44kSWqSIUeSJDXJkCNJkppkyJEkSU0y5EiSpCYZciRJUpNSVdNdgyZQknuA26a7jsbtDNw53UVsBrzOU8PrPDW8zpPnd6pq9nAbtpjqSjTpbquqBdNdRMuSLPUaTz6v89TwOk8Nr/P0cLpKkiQ1yZAjSZKaZMhpz+LpLmAz4DWeGl7nqeF1nhpe52ngjceSJKlJjuRIkqQmGXI2EUn+MMltSb6X5KRhtifJR7vty5M8c9C2etQ4r/OqJCuS3Jhk6dRWvmkZ4DrvmeSqJA8mOXF92qpnnNfYv+UBDXCdX9P9W7E8yZVJnjFoW02AqvK1kb+AGcD3gacCjwVuAvYass8fAf8FBHg2cM2gbX2N/zp321YBO0/3eWzsrwGv8xOAA4D3AyeuT1tf47vG3Tb/lifuOj8HeFy3/GL/bZ7alyM5m4YDge9V1Q+q6iHg34EjhuxzBPDZ6rka2DHJnAHbqmc811mDG/M6V9VPquo64Ffr21bA+K6xBjfIdb6yqu7uPl4NPGnQtho/Q86mYVfgR32f/7tbN8g+g7RVz3iuM0ABlyRZlmThpFW56RvP36R/z4MZ73Xyb3kw63udX0dvJHhD2moD+IvHm4YMs27o1+JG2meQtuoZz3UGOLiqfpzkCcClSb5dVd+c0ArbMJ6/Sf+eBzPe6+Tf8mAGvs5Jnk8v5Byyvm214RzJ2TT8N/Dkvs9PAn484D6DtFXPeK4zVbXu/SfA+fSGo/XbxvM36d/zYMZ1nfxbHthA1znJvsCngCOq6mfr01bjY8jZNFwHzEuyW5LHAq8CLhiyzwXAn3ff/nk2sKaq7hiwrXo2+Don2TbJ9gBJtgVeBNw8lcVvQsbzN+nf82A2+Dr5t7xexrzOSZ4CnAe8tqq+sz5tNX5OV20CqurhJCcAF9O7I//MqlqZ5A3d9jOA/6T3zZ/vAfcBfzFa22k4jY3eeK4zsAtwfhLo/f/q81V10RSfwiZhkOuc5P8ClgI7AI8keQu9b578wr/nsY3nGtN7WrZ/ywMY8N+MdwKPBz7WXdOHq2qB/zZPDX/xWJIkNcnpKkmS1CRDjiRJapIhR5IkNcmQI0mSmmTIkSRJTTLkSNooJFnbPfV63WvuBvRxZJK9JqE8kjwxybmT0fcox5yf5I+m8phSS/ydHEkbi/urav44+zgS+Cpwy6ANkmxRVQ+PtV/3K8BHbXhp6yfJFsB8YAG932eStJ4cyZG00Uqyf5LLuwdFXrzuie9J/jLJdUluSvLFJNskeQ7wUuCD3UjQ05IsSbKga7NzklXd8rFJzknyFXoPotw2yZldnzck+a2nQSeZm+TmvvZfSvKVJLcnOSHJ33Rtr06yU7ffkiSnJrkyyc1JDuzW79S1X97tv2+3/pQki5NcAnwWeA9wdHc+Ryc5sOvrhu59j756zktyUZLvJvmnvrr/MMn13bW6rFs35vlKLXAkR9LGYuskN3bLtwOvBE6j97yfnyY5Gng/cBxwXlV9EiDJ+4DXVdVpSS4AvlpV53bbRjveQcC+VXVXkn8Avl5VxyXZEbg2ydeq6t5R2u8N7AdsRe8XsP+uqvZL8mHgz4FTu/22rarnJHkucGbX7t3ADVV1ZJIX0As087v99wcOqar7kxwLLKiqE7rz2QF4bvdruYcB/wC8vGs3v6vnQeC2JKcBDwCf7Nrcvi58ASdvwPlKmxxDjqSNxW9MVyXZm14guLQLKzOAO7rNe3fhZkdgO3o/jb++Lq2qu7rlFwEvTXJi93kr4CnAraO0/0ZV3QPck2QN8JVu/Qpg3779vgBQVd9MskMXKg6hCydV9fUkj08yq9v/gqq6f4RjzgI+k2QevSdWb9m37bKqWgOQ5Bbgd4DHAd+sqtu7Y43nfKVNjiFH0sYqwMqqOmiYbWcBR1bVTd1ox6Ej9PEwj07LbzVkW/+oRYCXV9Vt61Hfg33Lj/R9foTf/Ld16LNzqjveUOv2G2005b30wtXLuhuzl4xQz9quhgxzfNiw85U2Od6TI2ljdRswO8lBAEm2TPL0btv2wB1JtgRe09fmnm7bOqvoTf/A6DcNXwy8Md2QUZL9xl/+rx3d9XkIvafWrwG+SVd3kkOBO6vqF8O0HXo+s4DV3fKxAxz7KuB5SXbrjrVuumoyz1faaBhyJG2UquohesHkA0luAm4EntNtfgdwDXAp8O2+Zv8O/G13M+3TgA8Bf5XkSnpP1x7Je+lN/Szvbi5+7wSeyt3d8c8AXtetOwVYkGQ5sAg4ZoS23wD2WnfjMfBPwD8muYLe9N2oquqnwELgvO4ant1tmszzlTYaPoVckiZJkiXAiVW1dLprkTZHjuRIkqQmOZIjSZKa5EiOJElqkiFHkiQ1yZAjSZKaZMiRJElNMuRIkqQmGXIkSVKT/g86rZVPILWfCAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Investigate feature importance for baseline Random Forest model\n",
    "\n",
    "# fit the baseline Random forest model\n",
    "forest_baseline_model.fit(X_train_full, y_train)\n",
    "\n",
    "# function to plot feature importance\n",
    "def plot_feature_importances(model):\n",
    "    n_features = X_train_full.shape[1]\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.barh(range(n_features), forest_baseline_model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train_full.columns.values) \n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.ylabel('Feature')\n",
    "\n",
    "plot_feature_importances(forest_baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Investigate feature importance for optimal Random Forest model\n",
    "\n",
    "# fit the optimal forest model\n",
    "forest_iterative_model.fit(X_train_full, y_train)\n",
    "\n",
    "# plot feature importance\n",
    "plot_feature_importances(forest_iterative_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's noted that age is the feature with highest importance to the model. We also note that credit_score, estimated salary and balance have significant import in both Random Forest models. Gender and country portray least importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3.4 Summary on Random Forest Modelling**\n",
    "\n",
    "A baseline Random Forest model with default parameters as well as an optimal Random Forest with optimised parameters are built. The optimal Random forest model (with a log loss of 0.36) that uses GridSearchCV produced optimal parameters, outperforms all the previous models i.e. the Logistic Regression Models (with log loss ranging from 0.433 to 0.575), the Decision Tree models (with log loss ranging from 0.406 to 7.7) and the baseline Random Forest model  that uses default paramaters (with log loss of 0.38). \n",
    "\n",
    "We used GridSearchCV to provide a range of parameter values to work with, guided by the graphical displays of the previous Decision Tree Model iterations when preparing the parameter grid. This final and best model has the following parameters: criterion='entropy', max_depth=9, min_samples_leaf=16, min_samples_split=91 and n_estimators=100.   \n",
    "\n",
    "A check on features of importance reveals age as the feature of highest importance for the Random Forest models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Overall Best Model Evaluation\n",
    "\n",
    "3 model types have been built i.e. Logistic Regression, Decision Trees and Random Forest models. For each model type, we've began with a baseline model and then created iterative models by tuning the model hyperparameters. Log loss has been the metric of choice for comparing the various models' performance. However, we have used other model metrics for different applications e.g. when establishing the best parameters for tuning Decision trees we made use of ROC curves and AUC. \n",
    "\n",
    "After the extensive modelling involving 14 models (baseline and iterative models); the best performing model turned out to be the optimal Random Forest model with a log loss of 0.36. This model was built using optimal parameters established via GridSearchCV. The worst performing model was the baseline Decision Tree Model i.e. the untuned/unpruned model with a log loss of 7.7. \n",
    "\n",
    "In this final modelling step, we shall implement and evaluate this best overall model. We shall use this model to carry out predictions and evaluate it's performance metrics i.e. Precision, Recall, Accuracy and f1 Score. We shall also visualize a confusion matrix for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision for best Random Forest model:  0.8657142857142858\n",
      "Testing Precision for best Random Forest model:  0.8590909090909091\n",
      "\n",
      "\n",
      "\n",
      "Training Recall for best Random Forest model:  0.3935064935064935\n",
      "Testing Recall for best Random Forest model:  0.38028169014084506\n",
      "\n",
      "\n",
      "\n",
      "Training Accuracy for best Random Forest model:  0.8629333333333333\n",
      "Testing Accuracy for best Random Forest model:  0.8644\n",
      "\n",
      "\n",
      "\n",
      "Training F1-Score for best Random Forest model:  0.5410714285714286\n",
      "Testing F1-Score for best Random Forest model:  0.5271966527196653\n"
     ]
    }
   ],
   "source": [
    "# Fit the model, on the training data only\n",
    "forest_iterative_model.fit(X_train_full, y_train)\n",
    "\n",
    "#  Predict on both the training and test data\n",
    "y_hat_train = forest_iterative_model.predict(X_train_full)\n",
    "y_hat_test = forest_iterative_model.predict(X_test_full)\n",
    "\n",
    "# Calculate precision, recall, accuracy, and F1 score of the best classifier on train and test data\n",
    "print('Training Precision for best Random Forest model: ', precision_score(y_train, y_hat_train))\n",
    "print('Testing Precision for best Random Forest model: ', precision_score(y_test, y_hat_test))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Recall for best Random Forest model: ', recall_score(y_train, y_hat_train))\n",
    "print('Testing Recall for best Random Forest model: ', recall_score(y_test, y_hat_test))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training Accuracy for best Random Forest model: ', accuracy_score(y_train, y_hat_train))\n",
    "print('Testing Accuracy for best Random Forest model: ', accuracy_score(y_test, y_hat_test))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('Training F1-Score for best Random Forest model: ', f1_score(y_train, y_hat_train))\n",
    "print('Testing F1-Score for best Random Forest model: ', f1_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the confusion matrix of the overall best model, on the test set\n",
    "cm = confusion_matrix(y_test, y_hat_test, labels=forest_iterative_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=forest_iterative_model.classes_)\n",
    "disp.plot()\n",
    "plt.grid(False) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation of the Overall Best Model - the Random Forest Model with GridSearchCV optimal parameters** \n",
    "\n",
    "With an accuracy of 86%, this model would assign the correct label about 86% of the time. This is better than a 'dummy' model - that would always predict the majority class (class 0) i.e a model that always predicted that no customer would leave the bank. Such a dummy model, would have an accuracy of 79.6%.\n",
    "\n",
    "The recall score is quite low at about 38% on the testing data; whereas the Precision is relatively higher at about 86%. This means that our model will miss out on a good number of customers who are leaving, and by the time it prescribes a customer as leaving, it will almost always be correct. This might be tolerable depending on the client's plans for those customers who are leaving. On the other hand, if the Bank wants to identify as many customers who are about to leave including being willing to err on the side of identifying 'loyal' customers as potential 'leavers', say for the purpose of carrying out mitigation measures to prevent this attrition, the model may have to be adjusted to allow for a higher recall and lower precision. The confusion matrix displays the distribution of the various predicted data versus true data for the test set. These would be theinputs to the calculations of the evaluation metrics of Recall, Precision, Accuracy and f1 Score.\n",
    "\n",
    "There may be need for further tuning of the model to improve on the f1 score which is relatively low at 53% for our overall best model.\n",
    "\n",
    "The training and test scores for each of the metrics are generally quite close, implying our overall best model is not overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Conclusions, Recommendations and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image_coins-1523383_1280.jpg\" width=\"300\" height=\"50\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image by Steve Buissinne from Pixabay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "The aim of this project analysis was to create a classification model for the client, ABC Multinational Bank, for use in predictions of customers that may leave the Bank. In predicting customer attrition (churn),  the client desires to create and implement intervention strategies targeting these customers with an aim to retain them before they actualize their exit. As well, the Bank would be able to make more informed decisions when it comes to offering certain products such as loans to its customers.\n",
    "\n",
    "3 types of classification models were built starting with their baseline then iterative models i.e.\n",
    "* Logistic Regression models\n",
    "* Decision Tree models\n",
    "* Random Forest models\n",
    "\n",
    "Tuning of hyperparameters to produce best models for each model type, using an iterative approach is done. Taking into account models produced by the various iterations, a total of 14 models are built with varying logloss. The optimised Random Forest model emerges the best performing model with a log loss of 0.36 against the other models with log loss of 0.38 to 7.7. This model is evaluated for its performance against certain metrics. In particular the model Recall is noted to be relatively low, while the Precision is relatively higher. Importance of features to the Random Forest models is also investigated. From the foregoing observations, the following recommendations will be made to the client, ABC Multinational Bank.\n",
    " \n",
    "### Recommendations\n",
    "1. The client will be advised to make use of the overall best model to predict customers that are likely to leave the Bank and target intervention strategies on these clients, aiming to retain them before they exit. \n",
    "2. This model may not be sufficient to decide on best candidates for provision of loans, especially judging from the performance of some evaluation metrics, and thus the client should be cautious in utilising it as such. \n",
    "3. The client will be advised to particularly pay attention to age of customers, credit_score, estimated salary and balance as features of importance in determining attrition. As such, the client should bear these aspects in mind when designing intervention strategies to retain customers.\n",
    "\n",
    "### Next Steps\n",
    "For additional insights, further analysis is proposed in the following areas;\n",
    "* Further tuning is proposed of the hyperparameters of the best performing model in order to lead to better performance metrics particularly the f1 Score. This further analysis could include use of XGBoost.\n",
    "* Adjustment of the model's Recall and Precision could be done in line with the focus of the Bank. A further discussion with the Bank to understand their needs and focus is needed e.g. *are the intervention measures likely to be too costly, in which case, the client would want a model that is even more precise?* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
